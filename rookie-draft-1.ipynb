{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-10T13:18:23.555757Z",
     "iopub.status.idle": "2022-04-10T13:18:23.557902Z",
     "shell.execute_reply.started": "2022-04-10T13:18:23.557664Z",
     "shell.execute_reply": "2022-04-10T13:18:23.557692Z"
    },
    "trusted": true,
    "cell_id": "00002-167c1848-bcba-4836-8bd1-3ddc4ef082b4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "79fc2f06",
    "execution_start": 1649613294094,
    "execution_millis": 6246,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 608.125
   },
   "source": "# !pip3 install sklearn\n# !pip3 install tqdm\n# !pip3 install tensorboardX\n!pip3 install timm\n!pip3 install torchmetrics",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: timm in /root/venv/lib/python3.7/site-packages (0.5.4)\nRequirement already satisfied: torchvision in /shared-libs/python3.7/py/lib/python3.7/site-packages (from timm) (0.12.0)\nRequirement already satisfied: torch>=1.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from timm) (1.11.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchvision->timm) (9.0.1)\nRequirement already satisfied: numpy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchvision->timm) (1.21.5)\nRequirement already satisfied: typing-extensions in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from torchvision->timm) (4.1.1)\nRequirement already satisfied: requests in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchvision->timm) (2.27.1)\nRequirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests->torchvision->timm) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests->torchvision->timm) (2.0.12)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->torchvision->timm) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->torchvision->timm) (1.26.9)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: torchmetrics in /root/venv/lib/python3.7/site-packages (0.7.3)\nRequirement already satisfied: pyDeprecate==0.3.* in /root/venv/lib/python3.7/site-packages (from torchmetrics) (0.3.2)\nRequirement already satisfied: torch>=1.3.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchmetrics) (1.11.0)\nRequirement already satisfied: numpy>=1.17.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchmetrics) (1.21.5)\nRequirement already satisfied: packaging in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: typing-extensions in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from torch>=1.3.1->torchmetrics) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from packaging->torchmetrics) (3.0.7)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cb8199f1",
    "execution_start": 1649613300343,
    "execution_millis": 1624,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:49.764587Z",
     "iopub.execute_input": "2022-04-10T13:17:49.764870Z",
     "iopub.status.idle": "2022-04-10T13:17:50.957957Z",
     "shell.execute_reply.started": "2022-04-10T13:17:49.764841Z",
     "shell.execute_reply": "2022-04-10T13:17:50.957030Z"
    },
    "trusted": true,
    "cell_id": "16027c27-e36b-43db-ae14-f77347475b56",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 370.375
   },
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch import optim\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom tensorboardX import SummaryWriter\nfrom timm.utils import AverageMeter\nfrom sklearn.model_selection import KFold\nimport random\nimport torchmetrics\n# from models.vgg import vgg",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "File paths to the data",
   "metadata": {
    "cell_id": "c0c469b487864c62bd7cac345ae51b33",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "source": "# Kaggle\nannotation_file_path = \"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\"\nimg_dir_path = \"../input/sorghum-id-fgvc-9/train_images\"\n\n# DeepNote\nannotation_file_path = \"data/train_cultivar_mapping.csv\"\nimg_dir_path = \"data/train_images\"",
   "metadata": {
    "cell_id": "305b546d5e1f47f7b631ae3c81ccfc69",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6d22b7dc",
    "execution_start": 1649613301967,
    "execution_millis": 55836,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 189
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": "Code for Resnet",
   "metadata": {
    "cell_id": "4baade19b6ee445d9893183fe7107333",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:50.960043Z",
     "iopub.execute_input": "2022-04-10T13:17:50.960330Z",
     "iopub.status.idle": "2022-04-10T13:17:51.003365Z",
     "shell.execute_reply.started": "2022-04-10T13:17:50.960293Z",
     "shell.execute_reply": "2022-04-10T13:17:51.002662Z"
    },
    "trusted": true,
    "cell_id": "00001-6ef05436-760b-40b3-bca2-481775b3abbb",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2bdc5d14",
    "execution_start": 1649613301992,
    "execution_millis": 3,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 4203
   },
   "source": "import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n__all__ = ['ResNet', 'resnet']\n\n\nmodel_urls = {\n    'resnet18': 'http://download.pytorch.org/models/resnet18-5c106cde.pth',\n    'resnet34': 'http://download.pytorch.org/models/resnet34-333f7ec4.pth',\n    'resnet50': 'http://download.pytorch.org/models/resnet50-19c8e357.pth',\n    'resnet101': 'http://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n    'resnet152': 'http://download.pytorch.org/models/resnet152-b121ed2d.pth',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\ndef cfg(depth):\n    depth_lst = [9, 18, 34, 50, 101, 152]\n    assert (depth in depth_lst), \"Error : ResNet depth should be either 18, 34, 50, 101, 152\"\n    cf_dict = {\n        '9' : (BasicBlock, [1,1, 1,1]),\n        '18' : (BasicBlock, [2,2, 2,2]),\n        '34' : (BasicBlock, [3,4, 6,3]),\n        '50' : (Bottleneck, [3,4, 6,3]),\n        '101': (Bottleneck, [3,4,23,3]),\n        '152': (Bottleneck, [3,8,36,3]),\n    }\n\n    return cf_dict[str(depth)]\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000, sln=False):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.sln = sln\n        # for the registration hook\n        self.gradients = None\n        self.activation = None\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n        if sln:\n            #self.fc_sln1 = nn.Linear(512 * 4 * 2, 512)\n            self.conv_sln1 = nn.Conv2d(512*block.expansion, 512, 3, 2, 1) # (4, 7)\n            #self.dropout1 = nn.Dropout(0.1)\n            self.conv_sln2 = nn.Conv2d(512, 256, 3, 2, 1) # (2, 4)\n            self.conv_sln3 = nn.Conv2d(256, 128, 3, 2, 1) # (1, 2)\n            #self.dropout2 = nn.Dropout(0.1)\n            #self.fc_sln2 = nn.Linear(512, 128)\n            #self.dropout3 = nn.Dropout(0.1)\n            self.fc_sln3 = nn.Linear(128*2, 1)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n\n    def activations_hook(self, grad):\n        self.gradients = grad\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        if self.sln:\n            x = self.relu(self.conv_sln1(x))\n            #x = self.dropout1(x)\n            x = self.relu(self.conv_sln2(x))\n\n            self.activation = x\n            x.register_hook(self.activations_hook)\n\n            #x = self.dropout2(x)\n            x = self.relu(self.conv_sln3(x))\n            #x = self.dropout3(x)\n\n            x = x.view(x.size(0), -1)\n            x = self.fc_sln3(x)\n            return x\n        \n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n    def get_activations_gradient(self):\n        return self.gradients\n\n    def get_activations(self):\n        return self.activation\n\n\ndef resnet(pretrained=False, depth=34, sln_head=False, **kwargs):\n    \"\"\"Constructs ResNet models for various depths\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        depth (int) : Integer input of either 18, 34, 50, 101, 152\n    \"\"\"\n    block, num_blocks = cfg(depth)\n    model = ResNet(block, num_blocks, sln=sln_head, **kwargs)\n    if (pretrained):\n        if sln_head:\n            print(\"| Downloading ImageNet fine-tuned ResNet-%d...\" %depth)\n            model.load_state_dict(model_zoo.load_url(model_urls['resnet%d' %depth]), strict=False)\n        else:\n            print(\"| Downloading ImageNet fine-tuned ResNet-%d...\" %depth)\n            model.load_state_dict(model_zoo.load_url(model_urls['resnet%d' %depth]), strict=False)\n            \n    model.fc = nn.Sequential(nn.Linear(model.fc.in_features * 7 * 7, 100))\n    return model\n",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e26c063b",
    "execution_start": 1649613301996,
    "execution_millis": 1072,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.549192Z",
     "iopub.execute_input": "2022-04-10T13:17:58.549858Z",
     "iopub.status.idle": "2022-04-10T13:17:58.827275Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.549819Z",
     "shell.execute_reply": "2022-04-10T13:17:58.826612Z"
    },
    "trusted": true,
    "cell_id": "00003-39870fad-6656-4e5f-90be-24b56652293e",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 417,
    "deepnote_output_heights": [
     21.1875,
     250
    ]
   },
   "source": "data = pd.read_csv(annotation_file_path)\ndata.cultivar.value_counts().hist()",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 5,
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "metadata": {}
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 368,
       "height": 248
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "325c18a0",
    "execution_start": 1649613303072,
    "execution_millis": 261,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:33:13.725789Z",
     "iopub.execute_input": "2022-04-10T13:33:13.726464Z",
     "iopub.status.idle": "2022-04-10T13:33:13.912933Z",
     "shell.execute_reply.started": "2022-04-10T13:33:13.726426Z",
     "shell.execute_reply": "2022-04-10T13:33:13.912225Z"
    },
    "trusted": true,
    "cell_id": "00004-323d2953-d100-49cb-90cf-531211f60f23",
    "owner_user_id": "936eb0aa-03ca-4152-ac6e-ea9f3d0f9c5e",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1763
   },
   "source": "import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torchvision.io import read_image\nfrom torchvision.transforms.functional import convert_image_dtype\nfrom sklearn import preprocessing\n\nclass CultivarDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file, )\n        \n        # remove this row, which the data preparer probably thought was funny to include\n        self.img_labels = self.img_labels[self.img_labels[\"image\"].str.contains(\".DS_Store\")==False]\n        print(self.img_labels)\n        \n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n        # one-hot encoding (very messy)\n        self.onehotenc = preprocessing.OneHotEncoder()\n        self.onehotenc.fit([[i] for i in self.img_labels['cultivar'].tolist()])\n        \n        # one-hot encoding (very messy)\n        self.labelenc = preprocessing.LabelEncoder()\n        self.labelenc.fit(self.img_labels['cultivar'].tolist())\n    \n    def to_onehot(self, lbl: str):\n        return torch.from_numpy(self.onehotenc.transform([[lbl]]).toarray()[0]).type(torch.LongTensor)\n    \n    def to_label(self, string: str):\n        return self.labelenc.transform([string])[0]\n\n    def __len__(self):\n        # print(f'length: {len(self.img_labels)}')\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        # print(f'sampling: {idx}')\n        img_path = os.path.join(self.img_dir, str(self.img_labels.iloc[idx, 0]))\n\n        # NOTE: when pytorch reads an image, it is immediately transformed into a uint8 Tensor with each channel ranging in [0, 255]\n        image = read_image(img_path)\n        label = self.to_label(self.img_labels.iloc[idx, 1])\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n#         print(label)\n        return image, label\n\nc = CultivarDataset(\n    annotations_file=annotation_file_path,\n    img_dir=img_dir_path\n)\n\nprint(c.to_label('PI_257599'))\nprint(c[0])\nprint(f'Anything else?: {c.img_labels[c.img_labels[\"image\"].str.contains(\"2017\")==False]}')",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": "                              image   cultivar\n0      2017-06-16__12-24-20-930.png  PI_257599\n1      2017-06-02__16-48-57-866.png  PI_154987\n2      2017-06-12__13-18-07-707.png   PI_92270\n3      2017-06-22__13-18-06-841.png  PI_152651\n4      2017-06-26__12-56-48-642.png  PI_176766\n...                             ...        ...\n22189  2017-06-16__12-27-16-266.png  PI_170787\n22190  2017-06-28__11-19-57-454.png  PI_156393\n22191  2017-06-28__10-20-32-417.png  PI_152923\n22192  2017-06-28__12-47-02-714.png  PI_257599\n22193  2017-06-04__13-12-56-053.png  PI_196586\n\n[22193 rows x 2 columns]\n73\n(tensor([[[ 93,  89,  92,  ...,  70,  77,  74],\n         [ 94,  82,  75,  ...,  63,  62,  62],\n         [103,  78,  74,  ...,  60,  63,  76],\n         ...,\n         [ 81,  64,  67,  ...,  85,  87,  91],\n         [ 82,  64,  64,  ...,  80,  76,  75],\n         [ 64,  57,  57,  ...,  62,  58,  54]],\n\n        [[ 56,  69,  86,  ...,  68,  70,  74],\n         [ 70,  87,  89,  ...,  66,  68,  70],\n         [ 87,  90,  87,  ...,  67,  67,  76],\n         ...,\n         [ 69,  70,  70,  ..., 100, 102,  99],\n         [ 69,  69,  69,  ...,  85,  85,  82],\n         [ 75,  70,  71,  ...,  78,  78,  78]],\n\n        [[ 29,  50,  57,  ...,  49,  53,  53],\n         [ 44,  69,  70,  ...,  55,  56,  60],\n         [ 55,  74,  67,  ...,  57,  58,  64],\n         ...,\n         [ 39,  53,  52,  ...,  67,  67,  67],\n         [ 39,  52,  51,  ...,  61,  56,  57],\n         [ 47,  59,  57,  ...,  62,  59,  58]]], dtype=torch.uint8), 73)\nAnything else?: Empty DataFrame\nColumns: [image, cultivar]\nIndex: []\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "65323b38",
    "execution_start": 1649613303308,
    "execution_millis": 70,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.842266Z",
     "iopub.execute_input": "2022-04-10T13:17:58.842771Z",
     "iopub.status.idle": "2022-04-10T13:17:58.925286Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.842733Z",
     "shell.execute_reply": "2022-04-10T13:17:58.924561Z"
    },
    "trusted": true,
    "cell_id": "00005-34a3ab74-eb6e-4209-8ce5-cce2bee3bd45",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 717
   },
   "source": "import torchvision.transforms as T\n\n# mean and std of each color channel\n# below is that of imagenet \nnorm_mean = [0.485, 0.456, 0.406]\nnorm_std = [0.229, 0.224, 0.225]\n\ntraining_data = CultivarDataset(\n    annotations_file=annotation_file_path,\n    img_dir=img_dir_path,\n    transform=T.Compose([\n        T.RandomEqualize(p=1), # if only this can be done AFTER the crop\n        T.ConvertImageDtype(torch.float), # we are given uint8 tensor, but we need a float tensor\n        # T.ColorJitter(brightness=.5, contrast=.7),\n        T.RandomCrop(size=(500, 500)),\n        T.RandomRotation(degrees=(-180, 180)),\n        T.CenterCrop(size=(224, 224)),\n        T.Normalize(norm_mean, norm_std)\n    ])\n)",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "                              image   cultivar\n0      2017-06-16__12-24-20-930.png  PI_257599\n1      2017-06-02__16-48-57-866.png  PI_154987\n2      2017-06-12__13-18-07-707.png   PI_92270\n3      2017-06-22__13-18-06-841.png  PI_152651\n4      2017-06-26__12-56-48-642.png  PI_176766\n...                             ...        ...\n22189  2017-06-16__12-27-16-266.png  PI_170787\n22190  2017-06-28__11-19-57-454.png  PI_156393\n22191  2017-06-28__10-20-32-417.png  PI_152923\n22192  2017-06-28__12-47-02-714.png  PI_257599\n22193  2017-06-04__13-12-56-053.png  PI_196586\n\n[22193 rows x 2 columns]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Notes on Hyperparameter:\n- https://arxiv.org/pdf/1803.09820.pdf\n- Momentum is usually always 0.9",
   "metadata": {
    "tags": [],
    "cell_id": "00006-9f1b17d8-aca6-496a-a653-0728b41aae5f",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 128.171875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "faa1b632",
    "execution_start": 1649613303365,
    "execution_millis": 16,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.926419Z",
     "iopub.execute_input": "2022-04-10T13:17:58.928301Z",
     "iopub.status.idle": "2022-04-10T13:17:58.933793Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.928269Z",
     "shell.execute_reply": "2022-04-10T13:17:58.931502Z"
    },
    "trusted": true,
    "cell_id": "00007-44ddf17f-5f66-44d2-9265-6dc819110937",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 171
   },
   "source": "# Hyperparameters\nlr = 1e-4\nmomentum = 0.9\nweight_decay = 1e-5\nepoches = 10\nk_fold = 3",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "58385167",
    "execution_start": 1649613303381,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.934868Z",
     "iopub.execute_input": "2022-04-10T13:17:58.935114Z",
     "iopub.status.idle": "2022-04-10T13:17:58.942549Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.935079Z",
     "shell.execute_reply": "2022-04-10T13:17:58.941214Z"
    },
    "trusted": true,
    "cell_id": "00008-1d2fa34e-5324-483c-9cf1-b3ce2e15c4d4",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 207
   },
   "source": "def set_random_seed(seed=0, deterministic=False):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    if deterministic:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a217eed9",
    "execution_start": 1649613303382,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.944252Z",
     "iopub.execute_input": "2022-04-10T13:17:58.944567Z",
     "iopub.status.idle": "2022-04-10T13:17:58.952672Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.944532Z",
     "shell.execute_reply": "2022-04-10T13:17:58.951826Z"
    },
    "trusted": true,
    "cell_id": "00009-b6274abe-8654-4055-b1a3-59c7ccf05eb4",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 585
   },
   "source": "def cultivar_train(model, data_loader_train, optimizer, criterion, metric, epoch, summary_writer, fold):\n    model.train()\n    optimizer.zero_grad()\n    loss_meter = AverageMeter()\n    # total_samples, correct = 0, 0\n    with tqdm(enumerate(data_loader_train), total=len(data_loader_train)) as pbar:\n        for idx, (samples, targets) in pbar:\n            samples = samples.cuda()\n            targets = targets.cuda()\n            out = model(samples)\n            pred = F.softmax(out)\n            loss = criterion(pred, targets)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            loss_meter.update(loss.item(), targets.size(0))\n\n            # Calculate accuracy\n            acc = metric(pred.argmax(1), targets)\n            # _, predicted = torch.max(pred.data, 1)\n            # total_samples += targets.size(0)\n            # correct += (predicted == targets).sum().item()\n            print(f\"Validation accuracy {acc}, loss {loss}\")\n            if idx%10 == 0:\n                summary_writer.add_scalar(f'Fold {fold}, acc/train', acc, epoch*len(data_loader_train)+idx)\n                summary_writer.add_scalar(f'Fold {fold}, loss/train', loss, epoch*len(data_loader_train)+idx)\n            pbar.set_description(f\"Train epoch {epoch}, loss: {loss_meter.avg: .4f}\")\n\n    return loss_meter.avg",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "64d6c234",
    "execution_start": 1649613303382,
    "execution_millis": 1,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.955090Z",
     "iopub.execute_input": "2022-04-10T13:17:58.955441Z",
     "iopub.status.idle": "2022-04-10T13:17:58.963978Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.955405Z",
     "shell.execute_reply": "2022-04-10T13:17:58.963103Z"
    },
    "trusted": true,
    "cell_id": "00010-538d1048-c03b-48e4-aedb-f228dbb9a9b5",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 513
   },
   "source": "def cultivar_val(model, data_loader_val, criterion, metric, epoch, summary_writer, fold):\n    model.eval()\n    loss_meter = AverageMeter()\n    # total_samples, correct = 0, 0\n    with tqdm(enumerate(data_loader_val), total=len(data_loader_val)) as pbar:\n        for idx, (samples, targets) in pbar:\n            samples = samples.cuda()\n            targets = targets.cuda()\n            out = model(samples)\n            pred = F.softmax(out)\n            loss = criterion(pred, targets)\n            loss_meter.update(loss.item(), targets.size(0))\n            \n            # Calculate accuracy\n            acc = metric(pred.argmax(1), target)\n            # _, predicted = torch.max(pred.data, 1)\n            # total_samples += targets.size(0)\n            # correct += (predicted == targets).sum().item()\n            print(f\"Validation accuracy {acc}, loss {loss}\")\n            if idx%10 == 0:\n                summary_writer.add_scalar(f'Fold {fold}, acc/val', acc, epoch*len(data_loader_val)+idx)\n                summary_writer.add_scalar(f'Fold {fold}, loss/val', loss, epoch*len(data_loader_val)+idx)\n            pbar.set_description(f\"Validation epoch {epoch}, loss: {loss: .4f}\")\n    \n    return loss_meter.avg",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "You need to run the `test.csv` and `train.csv` generation in `cultivardataset.ipynb` before running this!",
   "metadata": {
    "tags": [],
    "cell_id": "00011-1a3bd369-87e5-4f08-9715-de6f6c27fdb5",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "\nThe general procedure of k-fold is as follows:\n\n- Shuffle the dataset randomly.\n- Split the dataset into k groups\n- For each unique group:\n    - Take the group as a hold out or test data set\n    - Take the remaining groups as a training data set\n    - Fit a model on the training set and evaluate it on the test set\n    - Retain the evaluation score and discard the model\n- Summarize the skill of the model using the sample of model evaluation scores",
   "metadata": {
    "tags": [],
    "cell_id": "00012-8237d3ec-d9d8-49c9-a981-924713b2f8bd",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 291.515625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ea2cb96f",
    "execution_start": 1649613303394,
    "execution_millis": 1076,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.965384Z",
     "iopub.execute_input": "2022-04-10T13:17:58.965880Z",
     "iopub.status.idle": "2022-04-10T13:18:23.541213Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.965845Z",
     "shell.execute_reply": "2022-04-10T13:18:23.537890Z"
    },
    "trusted": true,
    "cell_id": "00013-ebdf3505-2169-4b1c-b983-745b237c2827",
    "owner_user_id": "9d557d55-fc23-4c8b-b1ac-104ba3539c98",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 2327
   },
   "source": "set_random_seed(seed=42)\nprint(\"Creating datasets...\")\ndataset = CultivarDataset(\n    annotations_file=annotation_file_path,\n    img_dir=img_dir_path,\n    transform=T.Compose([\n        T.RandomEqualize(p=1),\n        T.ConvertImageDtype(torch.float), # we are given uint8 tensor, but we need a float tensor\n        # T.ColorJitter(brightness=.5, contrast=.7),\n        T.RandomRotation(degrees=(-15, 15)),\n        T.RandomHorizontalFlip(p=0.5),\n        T.RandomVerticalFlip(p=0.5),\n        T.Resize(size=(224, 224)),\n        T.Normalize(norm_mean, norm_std)\n    ])\n)\n\n# dataset_val = CultivarDataset(\n#     annotations_file=\"data/test.csv\",\n#     img_dir=\"data/train_images\",\n#     transform=T.Compose([\n#         T.ConvertImageDtype(torch.float), # we are given uint8 tensor, but we need a float tensor\n#         # T.ColorJitter(brightness=.5, contrast=.7),\n#         T.CenterCrop(size=(224, 224)),\n#         T.Normalize(norm_mean, norm_std)\n#     ])\n# )\n\nsummary_writer = SummaryWriter()\nk_min_loss = [float('inf')]*k_fold\n\nkfold = KFold(n_splits=k_fold, shuffle=True)\n\nfor fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n    # Print\n    print(f'FOLD {fold}')\n    print('--------------------------------')\n    \n    # Sample elements randomly from a given list of ids, no replacement.\n    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n\n\n    print(\"Validation dataset created\")\n    data_loader_train = torch.utils.data.DataLoader(\n        dataset,\n        batch_size = 32,\n        sampler = train_subsampler,\n        num_workers = 2,\n        pin_memory = True,\n        drop_last = True\n    )\n    data_loader_val = torch.utils.data.DataLoader(\n        dataset,\n        batch_size = 32,\n        sampler = test_subsampler,\n        num_workers = 2,\n        pin_memory = True,\n        drop_last = False\n    )\n\n    print(\"Dataloader created\")\n    print(\"Creating model...\")\n    model = resnet(pretrained=True, sln_head=False)\n    model.cuda()\n    optimizer = optim.SGD(model.parameters(), momentum=momentum, nesterov=True, lr=lr, weight_decay=weight_decay)\n    criterion = nn.CrossEntropyLoss()\n    metric = torchmetrics.Accuracy(threshold=0.5, num_classes=100)\n\n    min_loss = float('inf')\n\n    print(\"Start Training\")\n    for epoch in range(epoches):\n        loss_train = cultivar_train(model, data_loader_train, optimizer, criterion, metric, epoch, summary_writer, fold)\n        loss_val = cultivar_val(model, data_loader_val, criterion, metric, epoch, summary_writer, fold)\n        min_loss = min(min_loss, loss_val)\n        if min_loss == loss_val:\n            save_state = {'model': model.state_dict(),\n                  'optimizer': optimizer.state_dict(),\n                  'epoch': epoch\n                  }\n\n            save_path = f'ckpt_epoch_{epoch}.pth'\n            print(f\"{save_path} saving...\")\n            torch.save(save_state, save_path)\n            print(f\"{save_path} saved\")\n\n        print(\"Writing to summarywriter...\")\n        # summary_writer.add_scalar(f'Fold {fold}, loss/train', loss_train, epoch)\n        # summary_writer.add_scalar(f'Fold {fold}, loss/val', loss_val, epoch)\n        summary_writer.add_scalar(f'Fold {fold}, min_loss', min_loss, epoch)\n        if min_loss == loss_val:\n            k_min_loss[fold] = min_loss\n\nprint(f\"K fold cross validate min loss average {sum(k_min_loss)/len(k_min_loss)}\")",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": "Creating datasets...\n                              image   cultivar\n0      2017-06-16__12-24-20-930.png  PI_257599\n1      2017-06-02__16-48-57-866.png  PI_154987\n2      2017-06-12__13-18-07-707.png   PI_92270\n3      2017-06-22__13-18-06-841.png  PI_152651\n4      2017-06-26__12-56-48-642.png  PI_176766\n...                             ...        ...\n22189  2017-06-16__12-27-16-266.png  PI_170787\n22190  2017-06-28__11-19-57-454.png  PI_156393\n22191  2017-06-28__10-20-32-417.png  PI_152923\n22192  2017-06-28__12-47-02-714.png  PI_257599\n22193  2017-06-04__13-12-56-053.png  PI_196586\n\n[22193 rows x 2 columns]\nFOLD 0\n--------------------------------\nValidation dataset created\nDataloader created\nCreating model...\n| Downloading ImageNet fine-tuned ResNet-34...\n",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c5673cf5f844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msln_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d841b2e3-7f2f-42e6-ae8e-6cea1c0a3631' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "deepnote_notebook_id": "02263764-213b-44c9-a49d-dd6ecb481d8f",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}