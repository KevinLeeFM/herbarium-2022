{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "866bf760",
    "execution_start": 1649521909192,
    "execution_millis": 2153,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:49.764587Z",
     "iopub.execute_input": "2022-04-10T13:17:49.764870Z",
     "iopub.status.idle": "2022-04-10T13:17:50.957957Z",
     "shell.execute_reply.started": "2022-04-10T13:17:49.764841Z",
     "shell.execute_reply": "2022-04-10T13:17:50.957030Z"
    },
    "trusted": true,
    "cell_id": "16027c27-e36b-43db-ae14-f77347475b56",
    "owner_user_id": "9d557d55-fc23-4c8b-b1ac-104ba3539c98",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 297
   },
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch import optim\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom tensorboardX import SummaryWriter\nfrom timm.utils import AverageMeter\nfrom sklearn.model_selection import KFold\nimport random\n# from models.vgg import vgg",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "File paths to the data",
   "metadata": {
    "cell_id": "c0c469b487864c62bd7cac345ae51b33",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "source": "# Kaggle\nannotation_file_path = \"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\"\nimg_dir_path = \"../input/sorghum-id-fgvc-9/train_images\"\n\n# DeepNote\nannotation_file_path = \"data/train_cultivar_mapping.csv\"\nimg_dir_path = \"data/train_images\"",
   "metadata": {
    "cell_id": "305b546d5e1f47f7b631ae3c81ccfc69",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 174
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Code for Resnet",
   "metadata": {
    "cell_id": "4baade19b6ee445d9893183fe7107333",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:50.960043Z",
     "iopub.execute_input": "2022-04-10T13:17:50.960330Z",
     "iopub.status.idle": "2022-04-10T13:17:51.003365Z",
     "shell.execute_reply.started": "2022-04-10T13:17:50.960293Z",
     "shell.execute_reply": "2022-04-10T13:17:51.002662Z"
    },
    "trusted": true,
    "cell_id": "00001-6ef05436-760b-40b3-bca2-481775b3abbb",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 4188
   },
   "source": "import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n__all__ = ['ResNet', 'resnet']\n\n\nmodel_urls = {\n    'resnet18': 'http://download.pytorch.org/models/resnet18-5c106cde.pth',\n    'resnet34': 'http://download.pytorch.org/models/resnet34-333f7ec4.pth',\n    'resnet50': 'http://download.pytorch.org/models/resnet50-19c8e357.pth',\n    'resnet101': 'http://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n    'resnet152': 'http://download.pytorch.org/models/resnet152-b121ed2d.pth',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\ndef cfg(depth):\n    depth_lst = [9, 18, 34, 50, 101, 152]\n    assert (depth in depth_lst), \"Error : ResNet depth should be either 18, 34, 50, 101, 152\"\n    cf_dict = {\n        '9' : (BasicBlock, [1,1, 1,1]),\n        '18' : (BasicBlock, [2,2, 2,2]),\n        '34' : (BasicBlock, [3,4, 6,3]),\n        '50' : (Bottleneck, [3,4, 6,3]),\n        '101': (Bottleneck, [3,4,23,3]),\n        '152': (Bottleneck, [3,8,36,3]),\n    }\n\n    return cf_dict[str(depth)]\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000, sln=False):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.sln = sln\n        # for the registration hook\n        self.gradients = None\n        self.activation = None\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n        if sln:\n            #self.fc_sln1 = nn.Linear(512 * 4 * 2, 512)\n            self.conv_sln1 = nn.Conv2d(512*block.expansion, 512, 3, 2, 1) # (4, 7)\n            #self.dropout1 = nn.Dropout(0.1)\n            self.conv_sln2 = nn.Conv2d(512, 256, 3, 2, 1) # (2, 4)\n            self.conv_sln3 = nn.Conv2d(256, 128, 3, 2, 1) # (1, 2)\n            #self.dropout2 = nn.Dropout(0.1)\n            #self.fc_sln2 = nn.Linear(512, 128)\n            #self.dropout3 = nn.Dropout(0.1)\n            self.fc_sln3 = nn.Linear(128*2, 1)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n\n    def activations_hook(self, grad):\n        self.gradients = grad\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        if self.sln:\n            x = self.relu(self.conv_sln1(x))\n            #x = self.dropout1(x)\n            x = self.relu(self.conv_sln2(x))\n\n            self.activation = x\n            x.register_hook(self.activations_hook)\n\n            #x = self.dropout2(x)\n            x = self.relu(self.conv_sln3(x))\n            #x = self.dropout3(x)\n\n            x = x.view(x.size(0), -1)\n            x = self.fc_sln3(x)\n            return x\n        \n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n    def get_activations_gradient(self):\n        return self.gradients\n\n    def get_activations(self):\n        return self.activation\n\n\ndef resnet(pretrained=False, depth=34, sln_head=False, **kwargs):\n    \"\"\"Constructs ResNet models for various depths\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        depth (int) : Integer input of either 18, 34, 50, 101, 152\n    \"\"\"\n    block, num_blocks = cfg(depth)\n    model = ResNet(block, num_blocks, sln=sln_head, **kwargs)\n    if (pretrained):\n        if sln_head:\n            print(\"| Downloading ImageNet fine-tuned ResNet-%d...\" %depth)\n            model.load_state_dict(model_zoo.load_url(model_urls['resnet%d' %depth]), strict=False)\n        else:\n            print(\"| Downloading ImageNet fine-tuned ResNet-%d...\" %depth)\n            model.load_state_dict(model_zoo.load_url(model_urls['resnet%d' %depth]), strict=False)\n            \n    model.fc = nn.Sequential(nn.Linear(model.fc.in_features * 7 * 7, 100))\n    return model\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-10T13:18:23.555757Z",
     "iopub.status.idle": "2022-04-10T13:18:23.557902Z",
     "shell.execute_reply.started": "2022-04-10T13:18:23.557664Z",
     "shell.execute_reply": "2022-04-10T13:18:23.557692Z"
    },
    "trusted": true,
    "cell_id": "00002-167c1848-bcba-4836-8bd1-3ddc4ef082b4",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 120
   },
   "source": "# !pip3 install sklearn\n# !pip3 install tqdm\n# !pip3 install tensorboardX\n# !pip3 install timm",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d56e62bd",
    "execution_start": 1649521911353,
    "execution_millis": 2015,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.549192Z",
     "iopub.execute_input": "2022-04-10T13:17:58.549858Z",
     "iopub.status.idle": "2022-04-10T13:17:58.827275Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.549819Z",
     "shell.execute_reply": "2022-04-10T13:17:58.826612Z"
    },
    "trusted": true,
    "cell_id": "00003-39870fad-6656-4e5f-90be-24b56652293e",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "data = pd.read_csv(annotation_file_path)\ndata.cultivar.value_counts().hist()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9e7ddcde",
    "execution_start": 1649521912883,
    "execution_millis": 4,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:33:13.725789Z",
     "iopub.execute_input": "2022-04-10T13:33:13.726464Z",
     "iopub.status.idle": "2022-04-10T13:33:13.912933Z",
     "shell.execute_reply.started": "2022-04-10T13:33:13.726426Z",
     "shell.execute_reply": "2022-04-10T13:33:13.912225Z"
    },
    "trusted": true,
    "cell_id": "00004-323d2953-d100-49cb-90cf-531211f60f23",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1305
   },
   "source": "import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torchvision.io import read_image\nfrom torchvision.transforms.functional import convert_image_dtype\nfrom sklearn import preprocessing\n\nclass CultivarDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file, )\n        \n        # remove this row, which the data preparer probably thought was funny to include\n        self.img_labels = self.img_labels[self.img_labels[\"image\"].str.contains(\".DS_Store\")==False]\n        print(self.img_labels)\n        \n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n        # one-hot encoding (very messy)\n        self.onehotenc = preprocessing.OneHotEncoder()\n        self.onehotenc.fit([[i] for i in self.img_labels['cultivar'].tolist()])\n        \n        # one-hot encoding (very messy)\n        self.labelenc = preprocessing.LabelEncoder()\n        self.labelenc.fit(self.img_labels['cultivar'].tolist())\n    \n    def to_onehot(self, lbl: str):\n        return torch.from_numpy(self.onehotenc.transform([[lbl]]).toarray()[0]).type(torch.LongTensor)\n    \n    def to_label(self, string: str):\n        return self.labelenc.transform([string])[0]\n\n    def __len__(self):\n        # print(f'length: {len(self.img_labels)}')\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        # print(f'sampling: {idx}')\n        img_path = os.path.join(self.img_dir, str(self.img_labels.iloc[idx, 0]))\n\n        # NOTE: when pytorch reads an image, it is immediately transformed into a uint8 Tensor with each channel ranging in [0, 255]\n        image = read_image(img_path)\n        label = self.to_label(self.img_labels.iloc[idx, 1])\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n#         print(label)\n        return image, label\n\nc = CultivarDataset(\n    annotations_file=annotation_file_path,\n    img_dir=img_dir_path,\n    transform=T.Compose([\n        T.RandomEqualize(p=1),\n        T.ConvertImageDtype(torch.float), # we are given uint8 tensor, but we need a float tensor\n        # T.ColorJitter(brightness=.5, contrast=.7),\n        T.RandomCrop(size=(500, 500)),\n        T.RandomRotation(degrees=(-180, 180)),\n        T.CenterCrop(size=(224, 224)),\n        T.Normalize(norm_mean, norm_std)\n    ])\n)\n\nprint(c.to_label('PI_257599'))\nprint(c[0])\nprint(f'Anything else?: {c.img_labels[c.img_labels[\"image\"].str.contains(\"2017\")==False]}')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a408fff5",
    "execution_start": 1649521912891,
    "execution_millis": 6,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.842266Z",
     "iopub.execute_input": "2022-04-10T13:17:58.842771Z",
     "iopub.status.idle": "2022-04-10T13:17:58.925286Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.842733Z",
     "shell.execute_reply": "2022-04-10T13:17:58.924561Z"
    },
    "trusted": true,
    "cell_id": "00005-34a3ab74-eb6e-4209-8ce5-cce2bee3bd45",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 423
   },
   "source": "import torchvision.transforms as T\n\n# mean and std of each color channel\n# below is that of imagenet \nnorm_mean = [0.485, 0.456, 0.406]\nnorm_std = [0.229, 0.224, 0.225]\n\ntraining_data = CultivarDataset(\n    annotations_file=annotation_file_path,\n    img_dir=img_dir_path,\n    transform=T.Compose([\n        T.RandomEqualize(p=1), # if only this can be done AFTER the crop\n        T.ConvertImageDtype(torch.float), # we are given uint8 tensor, but we need a float tensor\n        # T.ColorJitter(brightness=.5, contrast=.7),\n        T.RandomCrop(size=(500, 500)),\n        T.RandomRotation(degrees=(-180, 180)),\n        T.CenterCrop(size=(224, 224)),\n        T.Normalize(norm_mean, norm_std)\n    ])\n)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Notes on Hyperparameter:\n- https://arxiv.org/pdf/1803.09820.pdf\n- Momentum is usually always 0.9",
   "metadata": {
    "tags": [],
    "cell_id": "00006-9f1b17d8-aca6-496a-a653-0728b41aae5f",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 128.171875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7fb521b7",
    "execution_start": 1649521912901,
    "execution_millis": 3,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.926419Z",
     "iopub.execute_input": "2022-04-10T13:17:58.928301Z",
     "iopub.status.idle": "2022-04-10T13:17:58.933793Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.928269Z",
     "shell.execute_reply": "2022-04-10T13:17:58.931502Z"
    },
    "trusted": true,
    "cell_id": "00007-44ddf17f-5f66-44d2-9265-6dc819110937",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 171
   },
   "source": "# Hyperparameters\nlr = 1e-3\nmomentum = 0.9\nweight_decay = 1e-4\nepoches = 10\nk_fold = 4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d5d46ad0",
    "execution_start": 1649521912907,
    "execution_millis": 3,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.934868Z",
     "iopub.execute_input": "2022-04-10T13:17:58.935114Z",
     "iopub.status.idle": "2022-04-10T13:17:58.942549Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.935079Z",
     "shell.execute_reply": "2022-04-10T13:17:58.941214Z"
    },
    "trusted": true,
    "cell_id": "00008-1d2fa34e-5324-483c-9cf1-b3ce2e15c4d4",
    "owner_user_id": "936eb0aa-03ca-4152-ac6e-ea9f3d0f9c5e",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 207
   },
   "source": "def set_random_seed(seed=0, deterministic=False):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    if deterministic:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "22459c33",
    "execution_start": 1649521912915,
    "execution_millis": 3,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.944252Z",
     "iopub.execute_input": "2022-04-10T13:17:58.944567Z",
     "iopub.status.idle": "2022-04-10T13:17:58.952672Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.944532Z",
     "shell.execute_reply": "2022-04-10T13:17:58.951826Z"
    },
    "trusted": true,
    "cell_id": "00009-b6274abe-8654-4055-b1a3-59c7ccf05eb4",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 603
   },
   "source": "def cultivar_train(model, data_loader_train, optimizer, criterion, epoch, summary_writer, fold):\n    model.train()\n    optimizer.zero_grad()\n\n    loss_meter = AverageMeter()\n    total_samples, correct = 0, 0\n    with tqdm(enumerate(data_loader_train), total=len(data_loader_train)) as pbar:\n        for idx, (samples, targets) in pbar:\n            samples = samples.cuda()\n            targets = targets.cuda()\n            out = model(samples)\n            pred = F.softmax(out)\n            loss = criterion(pred, targets)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            loss_meter.update(loss.item(), targets.size(0))\n\n            # Calculate accuracy\n            _, predicted = torch.max(pred.data, 1)\n            total_samples += targets.size(0)\n            correct += (predicted == targets).sum().item()\n\n            if idx%10 == 0:\n                summary_writer.add_scalar(f'Fold {fold}, loss/train', loss_meter.avg, epoch*len(data_loader_train)+idx)\n            pbar.set_description(f\"Train epoch {epoch}, loss: {loss_meter.avg: .4f}\")\n\n    acc = correct/total_samples\n    print(f\"Test accuracy for epoch {epoch} is {acc: .4f}\")\n    return loss_meter.avg, acc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ba38b83b",
    "execution_start": 1649521912926,
    "execution_millis": 1,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.955090Z",
     "iopub.execute_input": "2022-04-10T13:17:58.955441Z",
     "iopub.status.idle": "2022-04-10T13:17:58.963978Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.955405Z",
     "shell.execute_reply": "2022-04-10T13:17:58.963103Z"
    },
    "trusted": true,
    "cell_id": "00010-538d1048-c03b-48e4-aedb-f228dbb9a9b5",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 513
   },
   "source": "def cultivar_val(model, data_loader_val, criterion, epoch, summary_writer, fold):\n    model.eval()\n    loss_meter = AverageMeter()\n    total_samples, correct = 0, 0\n    with tqdm(enumerate(data_loader_val), total=len(data_loader_val)) as pbar:\n        for idx, (samples, targets) in pbar:\n            samples = samples.cuda()\n            targets = targets.cuda()\n            out = model(samples)\n            pred = F.softmax(out)\n            loss = criterion(pred, targets)\n            loss_meter.update(loss.item(), targets.size(0))\n            \n            # Calculate accuracy\n            _, predicted = torch.max(pred.data, 1)\n            total_samples += targets.size(0)\n            correct += (predicted == targets).sum().item()\n\n            if idx%10 == 0:\n                summary_writer.add_scalar(f'Fold {fold}, loss/val', loss_meter.avg, epoch*len(data_loader_val)+idx)\n            pbar.set_description(f\"Validation epoch {epoch}, loss: {loss_meter.avg: .4f}\")\n    \n    acc = correct/total_samples\n    print(f\"Validation accuracy for epoch {epoch} is {acc}\")\n    return loss_meter.avg, acc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "You need to run the `test.csv` and `train.csv` generation in `cultivardataset.ipynb` before running this!",
   "metadata": {
    "tags": [],
    "cell_id": "00011-1a3bd369-87e5-4f08-9715-de6f6c27fdb5",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "\nThe general procedure of k-fold is as follows:\n\n- Shuffle the dataset randomly.\n- Split the dataset into k groups\n- For each unique group:\n    - Take the group as a hold out or test data set\n    - Take the remaining groups as a training data set\n    - Fit a model on the training set and evaluate it on the test set\n    - Retain the evaluation score and discard the model\n- Summarize the skill of the model using the sample of model evaluation scores",
   "metadata": {
    "tags": [],
    "cell_id": "00012-8237d3ec-d9d8-49c9-a981-924713b2f8bd",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 291.515625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "68be699a",
    "execution_start": 1649521912977,
    "execution_millis": 7795,
    "execution": {
     "iopub.status.busy": "2022-04-10T13:17:58.965384Z",
     "iopub.execute_input": "2022-04-10T13:17:58.965880Z",
     "iopub.status.idle": "2022-04-10T13:18:23.541213Z",
     "shell.execute_reply.started": "2022-04-10T13:17:58.965845Z",
     "shell.execute_reply": "2022-04-10T13:18:23.537890Z"
    },
    "trusted": true,
    "cell_id": "00013-ebdf3505-2169-4b1c-b983-745b237c2827",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1809
   },
   "source": "set_random_seed(seed=0)\nprint(\"Creating datasets...\")\ndataset = CultivarDataset(\n    annotations_file=annotation_file_path,\n    img_dir=img_dir_path,\n    transform=T.Compose([\n        T.RandomEqualize(p=1),\n        T.ConvertImageDtype(torch.float), # we are given uint8 tensor, but we need a float tensor\n        # T.ColorJitter(brightness=.5, contrast=.7),\n        T.RandomRotation(degrees=(-15, 15)),\n        T.RandomHorizontalFlip(p=0.5),\n        T.RandomVerticalFlip(p=0.5),\n        T.Resize(size=(224, 224)),\n        T.Normalize(norm_mean, norm_std)\n    ])\n)\n\n# dataset_val = CultivarDataset(\n#     annotations_file=\"data/test.csv\",\n#     img_dir=\"data/train_images\",\n#     transform=T.Compose([\n#         T.ConvertImageDtype(torch.float), # we are given uint8 tensor, but we need a float tensor\n#         # T.ColorJitter(brightness=.5, contrast=.7),\n#         T.CenterCrop(size=(224, 224)),\n#         T.Normalize(norm_mean, norm_std)\n#     ])\n# )\n\nsummary_writer = SummaryWriter()\nk_min_loss = [float('inf')]*k_fold\n\nkfold = KFold(n_splits=k_fold, shuffle=True)\n\nfor fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n    # Print\n    print(f'FOLD {fold}')\n    print('--------------------------------')\n    \n    # Sample elements randomly from a given list of ids, no replacement.\n    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n\n\n    print(\"Validation dataset created\")\n    data_loader_train = torch.utils.data.DataLoader(\n        dataset,\n        batch_size = 32,\n        sampler = train_subsampler,\n        num_workers = 3,\n        pin_memory = True,\n        drop_last = True\n    )\n    data_loader_val = torch.utils.data.DataLoader(\n        dataset,\n        batch_size = 32,\n        sampler = test_subsampler,\n        num_workers = 3,\n        pin_memory = True,\n        drop_last = False\n    )\n\n    print(\"Dataloader created\")\n    print(\"Creating model...\")\n    model = resnet(pretrained=True, sln_head=False)\n    model.cuda()\n    optimizer = optim.SGD(model.parameters(), momentum=momentum, nesterov=True, lr=lr, weight_decay=weight_decay)\n    criterion = nn.CrossEntropyLoss()\n\n    min_loss = float('inf')\n\n    print(\"Start Training\")\n    for epoch in range(epoches):\n        loss_train, acc_train = cultivar_train(model, data_loader_train, optimizer, criterion, epoch, summary_writer, fold)\n        loss_val, acc_val = cultivar_val(model, data_loader_val, criterion, epoch, summary_writer, fold)\n        min_loss = min(min_loss, loss_val)\n        if min_loss == loss_val:\n            save_state = {'model': model.state_dict(),\n                  'optimizer': optimizer.state_dict(),\n                  'max_accuracy': max_accuracy,\n                  'epoch': epoch\n                  }\n\n            save_path = f'ckpt_epoch_{epoch}.pth'\n            print(f\"{save_path} saving...\")\n            torch.save(save_state, save_path)\n            print(f\"{save_path} saved\")\n\n        print(\"Writing to summarywriter...\")\n        # summary_writer.add_scalar(f'Fold {fold}, loss/train', loss_train, epoch)\n        # summary_writer.add_scalar(f'Fold {fold}, loss/val', loss_val, epoch)\n        summary_writer.add_scalar(f'Fold {fold}, min_loss', min_loss, epoch)\n        summary_writer.add_scalar(f'Fold {fold}, acc/train', acc_train, epoch)\n        summary_writer.add_scalar(f'Fold {fold}, acc/val', acc_val, epoch)\n        if min_loss == loss_val:\n            k_min_loss[fold] = min_loss\n\nprint(f\"K fold cross validate min loss average {sum(k_min_loss)/len(k_min_loss)}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d841b2e3-7f2f-42e6-ae8e-6cea1c0a3631' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "deepnote_notebook_id": "02263764-213b-44c9-a49d-dd6ecb481d8f",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}