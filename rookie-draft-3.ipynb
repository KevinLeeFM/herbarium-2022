{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ff12ffbb",
    "execution_start": 1650122930006,
    "execution_millis": 8976,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:07:30.91094Z",
     "iopub.execute_input": "2022-04-30T16:07:30.911267Z",
     "iopub.status.idle": "2022-04-30T16:08:27.335233Z",
     "shell.execute_reply.started": "2022-04-30T16:07:30.911187Z",
     "shell.execute_reply": "2022-04-30T16:08:27.334409Z"
    },
    "trusted": true,
    "cell_id": "a3b7813c-6613-4bcb-8225-780726714671",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 791
   },
   "source": "!pip3 install sklearn\n!pip3 install tqdm\n!pip3 install tensorboardX\n!pip3 install timm\n!pip3 install torchmetrics\n!pip3 install albumentations",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5c6db781",
    "execution_start": 1650122938993,
    "execution_millis": 1420,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:08:27.337255Z",
     "iopub.execute_input": "2022-04-30T16:08:27.337523Z",
     "iopub.status.idle": "2022-04-30T16:08:34.06853Z",
     "shell.execute_reply.started": "2022-04-30T16:08:27.337485Z",
     "shell.execute_reply": "2022-04-30T16:08:34.067675Z"
    },
    "trusted": true,
    "cell_id": "00001-eb09c022-57c4-4a2c-bcff-4e9abcafecfa",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 334.375
   },
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch import optim\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom tensorboardX import SummaryWriter\nfrom timm.utils import AverageMeter\nimport random\nimport torchmetrics",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "File paths to the data",
   "metadata": {
    "tags": [],
    "cell_id": "00002-fa82ba06-a8ea-4d88-90ca-e4f242e7ac63",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6d22b7dc",
    "execution_start": 1650122940417,
    "execution_millis": 1,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:08:34.070022Z",
     "iopub.execute_input": "2022-04-30T16:08:34.070359Z",
     "iopub.status.idle": "2022-04-30T16:08:34.077467Z",
     "shell.execute_reply.started": "2022-04-30T16:08:34.07023Z",
     "shell.execute_reply": "2022-04-30T16:08:34.076795Z"
    },
    "trusted": true,
    "cell_id": "00003-6e0cedb4-be62-4026-bce2-f8426b226f81",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 189
   },
   "source": "# Kaggle\nannotation_file_path = \"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\"\nimg_dir_path = \"../input/sorghum-id-fgvc-9/train_images\"\n\n# DeepNote\n# annotation_file_path = \"data/train_cultivar_mapping.csv\"\n# img_dir_path = \"data/train_images\"",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "77911824",
    "execution_start": 1650122940423,
    "execution_millis": 642,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:08:34.081079Z",
     "iopub.execute_input": "2022-04-30T16:08:34.081547Z",
     "iopub.status.idle": "2022-04-30T16:08:35.846896Z",
     "shell.execute_reply.started": "2022-04-30T16:08:34.081511Z",
     "shell.execute_reply": "2022-04-30T16:08:35.846175Z"
    },
    "trusted": true,
    "cell_id": "00004-6ff3d695-9427-4a47-a498-5fc34aed08a9",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1719
   },
   "source": "import pandas as pd\nimport albumentations as A\nfrom pathlib import Path\nfrom albumentations.core.composition import Compose, OneOf\nfrom albumentations.pytorch import ToTensorV2\n\nclass DatasetParams:\n    img_size = 512\n    test_size = 0.2 # change to 0.2 later\n    filepaths = {\n        'train': Path(\"./\") / \"train.csv\",\n        'test': Path(\"./\") / \"test.csv\"\n    }\n    imgdirpath = img_dir_path\n\n    # mean and std of each color channel\n    # below is that of imagenet \n    norm_mean = [0.485, 0.456, 0.406]\n    norm_std = [0.229, 0.224, 0.225]\n\nDP = DatasetParams\n\nDP.universe = pd.read_csv(Path(\"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\"))\nDP.universe = DP.universe[DP.universe.image != '.DS_Store'] # sanitize inputs and remove the .DS_Store bulls**t\n\nDP.transforms = {\n    'train': Compose([\n                A.RandomResizedCrop(height=DP.img_size, width=DP.img_size),\n                A.Flip(p=0.5),\n                A.RandomRotate90(p=0.5),\n                A.ShiftScaleRotate(p=0.5),\n                A.HueSaturationValue(p=0.5),\n                A.OneOf([\n                    A.RandomBrightnessContrast(p=0.5),\n                    A.RandomGamma(p=0.5),\n                ], p=0.5),\n                A.OneOf([\n                    A.Blur(p=0.1),\n                    A.GaussianBlur(p=0.1),\n                    A.MotionBlur(p=0.1),\n                ], p=0.1),\n                A.OneOf([\n                    A.GaussNoise(p=0.1),\n                    A.ISONoise(p=0.1),\n                    A.GridDropout(ratio=0.5, p=0.2),\n                    A.CoarseDropout(max_holes=16, min_holes=8, max_height=16, max_width=16, min_height=8, min_width=8, p=0.2)\n                ], p=0.2),\n                A.Normalize(\n                    mean=DP.norm_mean,\n                    std=DP.norm_std,\n                ),\n                ToTensorV2(),\n            ]),\n    \n    'test': Compose([\n                A.Resize(height=DP.img_size, width=DP.img_size),\n                A.Normalize(\n                    mean=DP.norm_mean,\n                    std=DP.norm_std,\n                ),\n                ToTensorV2(),\n            ])\n}\n\nDP.transforms_vis = {\n    'train': Compose([\n                A.RandomResizedCrop(height=DP.img_size, width=DP.img_size),\n                A.Flip(p=0.5),\n                A.RandomRotate90(p=0.5),\n                A.ShiftScaleRotate(p=0.5),\n                A.HueSaturationValue(p=0.5),\n                A.OneOf([\n                    A.RandomBrightnessContrast(p=0.5),\n                    A.RandomGamma(p=0.5),\n                ], p=0.5),\n                A.OneOf([\n                    A.Blur(p=0.1),\n                    A.GaussianBlur(p=0.1),\n                    A.MotionBlur(p=0.1),\n                ], p=0.1),\n                A.OneOf([\n                    A.GaussNoise(p=0.1),\n                    A.ISONoise(p=0.1),\n                    A.GridDropout(ratio=0.5, p=0.2),\n                    A.CoarseDropout(max_holes=16, min_holes=8, max_height=16, max_width=16, min_height=8, min_width=8, p=0.2)\n                ], p=0.2),\n                ToTensorV2(),\n            ]),\n    \n    'test': Compose([\n                A.Resize(height=DP.img_size, width=DP.img_size),\n                ToTensorV2(),\n            ])\n}",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Split data into train and test ",
   "metadata": {
    "tags": [],
    "cell_id": "00005-253d2e0b-0a2e-409d-b9da-b680f9de21fc",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a8bdaf3e",
    "execution_start": 1650122941083,
    "execution_millis": 755,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:08:35.848236Z",
     "iopub.execute_input": "2022-04-30T16:08:35.848485Z",
     "iopub.status.idle": "2022-04-30T16:10:13.139256Z",
     "shell.execute_reply.started": "2022-04-30T16:08:35.848454Z",
     "shell.execute_reply": "2022-04-30T16:10:13.138504Z"
    },
    "trusted": true,
    "cell_id": "00006-b5d60b50-6f6f-4133-be86-7b35c440efb1",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1493
   },
   "source": "from pathlib import Path\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport random\n\nimg_labels = DP.universe\nprint(len(img_labels))\nprint(img_labels)\n\n# quick macro for dividing a database into two disjunct ones based on a function that returns boolean\ndef filter(dataframe, key, lb, yes, no):\n    for i, k in enumerate(dataframe[key].tolist()):\n        try:\n            if lb(k):\n                yes.loc[len(yes)] = dataframe.iloc[i]\n            else:\n                if no is not None:\n                    no.loc[len(no)] = dataframe.iloc[i]\n        except KeyError:\n            raise KeyError(f'Failed at {k}, {i}')\n            \n\ntrain = pd.DataFrame(columns=['image', 'cultivar'])\ntest = pd.DataFrame(columns=['image', 'cultivar'])\nimg_to_split = pd.DataFrame(columns=['image', 'cultivar'])\n\n# isolate all class with only 1 training sample and put them in train\ncounts = img_labels['cultivar'].value_counts()\nprint(counts)\nfilter(img_labels, 'cultivar', lambda cultivar: counts[cultivar] == 1, train, img_to_split)\n\n\nimgs = img_to_split['image'].tolist()\nlabels = img_to_split['cultivar'].tolist()\n\nprint(len(imgs), len(labels))\n\n# use train_test_split with stratify to split class with multiple training samples\ntrain_split, test_split = train_test_split(imgs, test_size=DP.test_size, stratify=labels)\n# print('train', train_split)\n# print('test_split', test_split, len(test_split))\n\nfilter(img_to_split, 'image', lambda image: image in train_split, train, test)\n\n# print('train', train)\n# print('test', test)\n\nassert(len(img_labels) == len(train) + len(test))\n\ntrain.to_csv(DP.filepaths['train'], index=False)\ntest.to_csv(DP.filepaths['test'], index=False)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Define the dataset",
   "metadata": {
    "tags": [],
    "cell_id": "00007-c7731ebf-1f84-4e54-9dcd-69524aa69bc1",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cf9d8389",
    "execution_start": 1650122941844,
    "execution_millis": 40,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:10:13.14067Z",
     "iopub.execute_input": "2022-04-30T16:10:13.140943Z",
     "iopub.status.idle": "2022-04-30T16:10:13.284804Z",
     "shell.execute_reply.started": "2022-04-30T16:10:13.140908Z",
     "shell.execute_reply": "2022-04-30T16:10:13.283546Z"
    },
    "trusted": true,
    "cell_id": "00008-69591e30-921a-49a1-bc1c-521de497950d",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1601
   },
   "source": "import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision.io import read_image\nfrom torchvision.transforms.functional import convert_image_dtype\nimport cv2\nfrom sklearn import preprocessing\n\nclass CultivarDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n        self.labelenc = preprocessing.LabelEncoder()\n        self.labelenc.fit(self.img_labels['cultivar'].tolist())      \n\n    def to_label(self, string: str):\n        return self.labelenc.transform([string])[0]  \n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n\n        # NOTE: when pytorch reads an image, it is immediately transformed into a uint8 Tensor with each channel ranging in [0, 255]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        label = self.to_label(self.img_labels.iloc[idx, 1])\n\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.target_transform:\n            label = self.target_transform(label)\n        \n        return image, label\n\n# small test to make sure it's working as intended\nc = CultivarDataset(\n    annotations_file=DP.filepaths['train'],\n    img_dir=DP.imgdirpath\n)\n\nprint(c.to_label('PI_257599'))\nprint(c[0])\nprint(f'Make sure there is no garbage data: {c.img_labels[c.img_labels[\"image\"].str.contains(\"2017\")==False]}')\n    ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a03c797a",
    "execution_start": 1650122941931,
    "execution_millis": 45,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:10:13.286154Z",
     "iopub.execute_input": "2022-04-30T16:10:13.286439Z",
     "iopub.status.idle": "2022-04-30T16:10:13.467237Z",
     "shell.execute_reply.started": "2022-04-30T16:10:13.286405Z",
     "shell.execute_reply": "2022-04-30T16:10:13.466479Z"
    },
    "trusted": true,
    "cell_id": "00009-93904b17-aef8-4a75-a32b-976a47b1fc64",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 953
   },
   "source": "datasets = {\n    'train': CultivarDataset(\n                annotations_file=DP.filepaths['train'],\n                img_dir=DP.imgdirpath,\n                transform=DP.transforms['train']\n            ),\n    'test': CultivarDataset(\n                annotations_file=DP.filepaths['test'],\n                img_dir=DP.imgdirpath,\n                transform=DP.transforms['test']\n            )\n}\n\nprint(datasets['train'][0])\nprint(datasets['test'][0])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e26c063b",
    "execution_start": 1650122941976,
    "execution_millis": 1478,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:10:13.468453Z",
     "iopub.execute_input": "2022-04-30T16:10:13.46869Z",
     "iopub.status.idle": "2022-04-30T16:10:13.711315Z",
     "shell.execute_reply.started": "2022-04-30T16:10:13.468658Z",
     "shell.execute_reply": "2022-04-30T16:10:13.710621Z"
    },
    "trusted": true,
    "cell_id": "00010-bee07ba0-a591-4b99-bd19-a01c8cb08a32",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 417.1875,
    "deepnote_output_heights": [
     21.1875,
     250
    ]
   },
   "source": "data = pd.read_csv(annotation_file_path)\ndata.cultivar.value_counts().hist()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Notes on Hyperparameter:\n- https://arxiv.org/pdf/1803.09820.pdf\n- Momentum is usually always 0.9",
   "metadata": {
    "tags": [],
    "cell_id": "00011-0244d4a3-f04d-44a1-877e-8207b0b4e41d",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 128.171875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "45a2a773",
    "execution_start": 1650122943169,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:10:13.712418Z",
     "iopub.execute_input": "2022-04-30T16:10:13.712662Z",
     "iopub.status.idle": "2022-04-30T16:10:13.719529Z",
     "shell.execute_reply.started": "2022-04-30T16:10:13.712628Z",
     "shell.execute_reply": "2022-04-30T16:10:13.718678Z"
    },
    "trusted": true,
    "cell_id": "00012-61f78cd2-5f56-40d2-a4ee-5827cd94af8d",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 351
   },
   "source": "class CustomEffNet(nn.Module):\n    def __init__(self, model_name='tf_efficientnet_b0_ns', pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.model.get_classifier().in_features\n#         self.model.fc = nn.Linear(in_features, CFG.num_classes)\n        self.model.classifier = nn.Sequential(\n            nn.Linear(in_features, in_features),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(in_features, 100)\n        )\n\n    def forward(self, x):\n        x = self.model(x)\n        return x",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fba592ed",
    "execution_start": 1650122943170,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:10:13.722336Z",
     "iopub.execute_input": "2022-04-30T16:10:13.722812Z",
     "iopub.status.idle": "2022-04-30T16:10:13.727918Z",
     "shell.execute_reply.started": "2022-04-30T16:10:13.722762Z",
     "shell.execute_reply": "2022-04-30T16:10:13.727107Z"
    },
    "trusted": true,
    "cell_id": "00013-3e8d442e-610e-49fe-bc84-63fa5ec3f051",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 171
   },
   "source": "# Hyperparameters\nlr = 1e-4\nmax_lr = 1e-3\nmomentum = 0.9\nweight_decay = 1e-5\nepoches = 25\nbatch_size = 8\ntemperature = 0.1\nexp_name = 'save_9'",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "58385167",
    "execution_start": 1650122943170,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:10:13.729376Z",
     "iopub.execute_input": "2022-04-30T16:10:13.729644Z",
     "iopub.status.idle": "2022-04-30T16:10:13.736927Z",
     "shell.execute_reply.started": "2022-04-30T16:10:13.729609Z",
     "shell.execute_reply": "2022-04-30T16:10:13.73614Z"
    },
    "trusted": true,
    "cell_id": "00014-2593cb1f-3416-4255-bd93-6e5d579657e8",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 207
   },
   "source": "def set_random_seed(seed=0, deterministic=False):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    if deterministic:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2721b579",
    "execution_start": 1650122943171,
    "execution_millis": 1,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:10:13.738156Z",
     "iopub.execute_input": "2022-04-30T16:10:13.738522Z",
     "iopub.status.idle": "2022-04-30T16:10:13.749228Z",
     "shell.execute_reply.started": "2022-04-30T16:10:13.73847Z",
     "shell.execute_reply": "2022-04-30T16:10:13.748353Z"
    },
    "trusted": true,
    "cell_id": "00015-af2fb79a-d9b3-40a8-8862-30ecb7f4fc11",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 585
   },
   "source": "def cultivar_train(model, data_loader_train, optimizer, scheduler, criterion, metric, epoch, summary_writer):\n    model.train()\n    optimizer.zero_grad()\n    loss_meter = AverageMeter()\n    acc_meter = AverageMeter()\n    # total_samples, correct = 0, 0\n    with tqdm(enumerate(data_loader_train), total=len(data_loader_train)) as pbar:\n        for idx, (samples, targets) in pbar:\n            optimizer.zero_grad()\n            samples = samples.cuda()\n            targets = targets.cuda()\n            out = model(samples)\n            loss = criterion(out, targets)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            loss_meter.update(loss.item(), targets.size(0))\n\n            # Calculate accuracy\n            pred = F.softmax(out)\n            acc = metric(pred.argmax(1).cpu(), targets.cpu())\n            acc_meter.update(acc, 1)\n            # _, predicted = torch.max(pred.data, 1)\n            # total_samples += targets.size(0)\n            # correct += (predicted == targets).sum().item()\n            if idx%10==0:\n                summary_writer.add_scalar(f'lr', optimizer.param_groups[0]['lr'], epoch*len(data_loader_train)+idx)\n            pbar.set_description(f\"Train epoch {epoch}, loss: {loss: .4f}, accuracy: {acc: .4f}, lr: {optimizer.param_groups[0]['lr']: .6f}\")\n\n    return loss_meter.avg, acc_meter.avg",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3e95c8d",
    "execution_start": 1650122943174,
    "execution_millis": 2,
    "owner_user_id": "936eb0aa-03ca-4152-ac6e-ea9f3d0f9c5e",
    "execution": {
     "iopub.status.busy": "2022-04-30T16:10:13.750615Z",
     "iopub.execute_input": "2022-04-30T16:10:13.750946Z",
     "iopub.status.idle": "2022-04-30T16:10:13.761888Z",
     "shell.execute_reply.started": "2022-04-30T16:10:13.750912Z",
     "shell.execute_reply": "2022-04-30T16:10:13.76113Z"
    },
    "trusted": true,
    "cell_id": "00016-c4b772e1-263d-4c30-bb9b-5c1e424995b0",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 477
   },
   "source": "@torch.no_grad()\ndef cultivar_val(model, data_loader_val, criterion, metric, epoch):\n    model.eval()\n    loss_meter = AverageMeter()\n    acc_meter = AverageMeter()\n    # total_samples, correct = 0, 0\n    with tqdm(enumerate(data_loader_val), total=len(data_loader_val)) as pbar:\n        for idx, (samples, targets) in pbar:\n            samples = samples.cuda()\n            targets = targets.cuda()\n            out = model(samples)\n            loss = criterion(out, targets)\n            loss_meter.update(loss.item(), targets.size(0))\n\n            # Calculate accuracy\n            pred = F.softmax(out)\n            acc = metric(pred.argmax(1).cpu(), targets.cpu())\n            acc_meter.update(acc, 1)\n            # _, predicted = torch.max(pred.data, 1)\n            # total_samples += targets.size(0)\n            # correct += (predicted == targets).sum().item()\n            pbar.set_description(f\"Validation epoch {epoch}, loss: {loss: .4f}, accuracy: {acc: .4f}\")\n    \n    return loss_meter.avg, acc_meter.avg",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "You need to run the `test.csv` and `train.csv` generation in `cultivardataset.ipynb` before running this!",
   "metadata": {
    "tags": [],
    "cell_id": "00017-26f62f76-5e9c-4c8b-8176-0e656dda44cb",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "\nThe general procedure of k-fold is as follows:\n\n- Shuffle the dataset randomly.\n- Split the dataset into k groups\n- For each unique group:\n    - Take the group as a hold out or test data set\n    - Take the remaining groups as a training data set\n    - Fit a model on the training set and evaluate it on the test set\n    - Retain the evaluation score and discard the model\n- Summarize the skill of the model using the sample of model evaluation scores",
   "metadata": {
    "tags": [],
    "cell_id": "00018-afe826b9-13aa-4b48-b0b9-a61a757f44e9",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 291.515625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4c858027",
    "execution_start": 1650122943226,
    "execution_millis": 2118,
    "execution": {
     "iopub.status.busy": "2022-04-30T16:10:13.764528Z",
     "iopub.execute_input": "2022-04-30T16:10:13.764728Z",
     "iopub.status.idle": "2022-04-30T16:12:29.37484Z",
     "shell.execute_reply.started": "2022-04-30T16:10:13.764706Z",
     "shell.execute_reply": "2022-04-30T16:12:29.373694Z"
    },
    "trusted": true,
    "cell_id": "00019-5522a799-9846-43f8-a958-f4a273d35e70",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1489.6875,
    "deepnote_output_heights": [
     null,
     40.375
    ]
   },
   "source": "import timm\nfrom timm.loss import SoftTargetCrossEntropy, LabelSmoothingCrossEntropy\n\nset_random_seed(seed=42)\nprint(\"Creating datasets...\")\n\nsummary_writer = SummaryWriter(exp_name)\n\nprint(\"Validation dataset created\")\ndata_loader_train = torch.utils.data.DataLoader(\n    datasets['train'],\n    batch_size = batch_size,\n    num_workers = 2,\n    shuffle=True,\n    pin_memory = True,\n    drop_last = True\n)\n\ndata_loader_val = torch.utils.data.DataLoader(\n    datasets['test'],\n    batch_size = batch_size,\n    num_workers = 2,\n    shuffle=False,\n    pin_memory = True,\n    drop_last = False\n)\n\nprint(\"Dataloader created\")\nprint(\"Creating model...\")\nmodel = CustomEffNet(model_name='tf_efficientnet_b5_ns', pretrained=True)\nmodel.cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n                                                        epochs=epoches, steps_per_epoch=len(data_loader_train),\n                                                        max_lr=max_lr, pct_start=0.2, \n                                                        div_factor=1e3, final_div_factor=1e3)\ncriterion = LabelSmoothingCrossEntropy(smoothing=temperature)\nmetric = torchmetrics.Accuracy(threshold=0.5, num_classes=100)\n\nmin_loss = float('inf')\n\nprint(\"Start Training\")\nfor epoch in range(epoches):\n    loss_train, acc_train = cultivar_train(model, data_loader_train, optimizer, scheduler, criterion, metric, epoch, summary_writer)\n    loss_val, acc_val = cultivar_val(model, data_loader_val, criterion, metric, epoch)\n    min_loss = min(min_loss, loss_val)\n    if min_loss == loss_val:\n        save_state = {'model': model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'epoch': epoch\n                }\n\n        save_path = f'ckpt_epoch_{epoch}.pth'\n        print(f\"{save_path} saving...\")\n        torch.save(save_state, save_path)\n        print(f\"{save_path} saved\")\n\n    print(\"Writing to summarywriter...\")\n    summary_writer.add_scalar(f'Loss/train', loss_train, epoch)\n    summary_writer.add_scalar(f'Loss/val', loss_val, epoch)\n    summary_writer.add_scalar(f'Acc/train', acc_train, epoch)\n    summary_writer.add_scalar(f'Acc/val', acc_val, epoch)\n    summary_writer.add_scalar(f'Min_loss', min_loss, epoch)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d841b2e3-7f2f-42e6-ae8e-6cea1c0a3631' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "deepnote_notebook_id": "9385fda4-279f-4e2f-9203-43a325e55a4d",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}