{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ff12ffbb",
    "execution_start": 1650122930006,
    "execution_millis": 8976,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:38:49.140314Z",
     "iopub.execute_input": "2022-04-17T04:38:49.14102Z",
     "iopub.status.idle": "2022-04-17T04:39:45.638416Z",
     "shell.execute_reply.started": "2022-04-17T04:38:49.140978Z",
     "shell.execute_reply": "2022-04-17T04:39:45.637495Z"
    },
    "trusted": true,
    "cell_id": "ab0dedb4-097c-492e-90bd-95f74f258fea",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 171
   },
   "source": "!pip3 install sklearn\n!pip3 install tqdm\n!pip3 install tensorboardX\n!pip3 install timm\n!pip3 install torchmetrics\n!pip3 install albumentations",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5c6db781",
    "execution_start": 1650122938993,
    "execution_millis": 1420,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:39:45.640764Z",
     "iopub.execute_input": "2022-04-17T04:39:45.641064Z",
     "iopub.status.idle": "2022-04-17T04:39:45.649087Z",
     "shell.execute_reply.started": "2022-04-17T04:39:45.641009Z",
     "shell.execute_reply": "2022-04-17T04:39:45.648285Z"
    },
    "trusted": true,
    "cell_id": "00001-fa5356e9-5c26-4bec-ae3f-062aef3644cf",
    "owner_user_id": "936eb0aa-03ca-4152-ac6e-ea9f3d0f9c5e",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 279
   },
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch import optim\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom tensorboardX import SummaryWriter\nfrom timm.utils import AverageMeter\nimport random\nimport torchmetrics",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "File paths to the data",
   "metadata": {
    "tags": [],
    "cell_id": "00002-853127dd-8c81-4ee3-8a85-d0dfe2543ec2",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6d22b7dc",
    "execution_start": 1650122940417,
    "execution_millis": 1,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:39:45.650928Z",
     "iopub.execute_input": "2022-04-17T04:39:45.651276Z",
     "iopub.status.idle": "2022-04-17T04:39:45.657584Z",
     "shell.execute_reply.started": "2022-04-17T04:39:45.65118Z",
     "shell.execute_reply": "2022-04-17T04:39:45.656817Z"
    },
    "trusted": true,
    "cell_id": "00003-e7364ebf-747a-4edf-acb1-4aa69f5dfc86",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 189
   },
   "source": "# Kaggle\nannotation_file_path = \"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\"\nimg_dir_path = \"../input/sorghum-id-fgvc-9/train_images\"\n\n# DeepNote\n# annotation_file_path = \"data/train_cultivar_mapping.csv\"\n# img_dir_path = \"data/train_images\"",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "77911824",
    "execution_start": 1650122940423,
    "execution_millis": 642,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:39:45.660338Z",
     "iopub.execute_input": "2022-04-17T04:39:45.660845Z",
     "iopub.status.idle": "2022-04-17T04:39:45.726951Z",
     "shell.execute_reply.started": "2022-04-17T04:39:45.660814Z",
     "shell.execute_reply": "2022-04-17T04:39:45.726205Z"
    },
    "trusted": true,
    "cell_id": "00004-dc9c3027-bd06-44ca-b5eb-84277e44b48f",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1755
   },
   "source": "import pandas as pd\nimport albumentations as A\nfrom pathlib import Path\nfrom albumentations.core.composition import Compose, OneOf\nfrom albumentations.pytorch import ToTensorV2\n\nclass DatasetParams:\n    img_size = 512\n    test_size = 0.2 # change to 0.2 later\n    filepaths = {\n        'train': Path(\"./\") / \"train.csv\",\n        'test': Path(\"./\") / \"test.csv\"\n    }\n    imgdirpath = img_dir_path\n\n    # mean and std of each color channel\n    # below is that of imagenet \n    norm_mean = [0.485, 0.456, 0.406]\n    norm_std = [0.229, 0.224, 0.225]\n\nDP = DatasetParams\n\nDP.universe = pd.read_csv(Path(\"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\"))\nDP.universe = DP.universe[DP.universe.image != '.DS_Store'] # sanitize inputs and remove the .DS_Store bulls**t\n\nDP.transforms = {\n    'train': Compose([\n                A.RandomResizedCrop(height=DP.img_size, width=DP.img_size),\n                A.Flip(p=0.5),\n                A.RandomRotate90(p=0.5),\n                A.ShiftScaleRotate(p=0.5),\n                A.HueSaturationValue(p=0.5),\n                A.OneOf([\n                    A.RandomBrightnessContrast(p=0.5),\n                    A.RandomGamma(p=0.5),\n                ], p=0.5),\n                A.OneOf([\n                    A.Blur(p=0.1),\n                    A.GaussianBlur(p=0.1),\n                    A.MotionBlur(p=0.1),\n                ], p=0.1),\n                A.OneOf([\n                    A.GaussNoise(p=0.1),\n                    A.ISONoise(p=0.1),\n                    A.GridDropout(ratio=0.5, p=0.2),\n                    A.CoarseDropout(max_holes=16, min_holes=8, max_height=16, max_width=16, min_height=8, min_width=8, p=0.2)\n                ], p=0.2),\n                A.Normalize(\n                    mean=DP.norm_mean,\n                    std=DP.norm_std,\n                ),\n                ToTensorV2(),\n            ]),\n    \n    'test': Compose([\n                A.Resize(height=DP.img_size, width=DP.img_size),\n                A.Normalize(\n                    mean=DP.norm_mean,\n                    std=DP.norm_std,\n                ),\n                ToTensorV2(),\n            ])\n}\n\nDP.transforms_vis = {\n    'train': Compose([\n                A.RandomResizedCrop(height=DP.img_size, width=DP.img_size),\n                A.Flip(p=0.5),\n                A.RandomRotate90(p=0.5),\n                A.ShiftScaleRotate(p=0.5),\n                A.HueSaturationValue(p=0.5),\n                A.OneOf([\n                    A.RandomBrightnessContrast(p=0.5),\n                    A.RandomGamma(p=0.5),\n                ], p=0.5),\n                A.OneOf([\n                    A.Blur(p=0.1),\n                    A.GaussianBlur(p=0.1),\n                    A.MotionBlur(p=0.1),\n                ], p=0.1),\n                A.OneOf([\n                    A.GaussNoise(p=0.1),\n                    A.ISONoise(p=0.1),\n                    A.GridDropout(ratio=0.5, p=0.2),\n                    A.CoarseDropout(max_holes=16, min_holes=8, max_height=16, max_width=16, min_height=8, min_width=8, p=0.2)\n                ], p=0.2),\n                ToTensorV2(),\n            ]),\n    \n    'test': Compose([\n                A.Resize(height=DP.img_size, width=DP.img_size),\n                ToTensorV2(),\n            ])\n}",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Split data into train and test ",
   "metadata": {
    "tags": [],
    "cell_id": "00005-d65d7203-8825-4c40-ad0f-fbdc43236550",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a8bdaf3e",
    "execution_start": 1650122941083,
    "execution_millis": 755,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:39:45.728095Z",
     "iopub.execute_input": "2022-04-17T04:39:45.728419Z",
     "iopub.status.idle": "2022-04-17T04:41:24.957249Z",
     "shell.execute_reply.started": "2022-04-17T04:39:45.728382Z",
     "shell.execute_reply": "2022-04-17T04:41:24.956453Z"
    },
    "trusted": true,
    "cell_id": "00006-9292c026-ec98-44a5-9bc1-e18cadf6a05d",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 981
   },
   "source": "from pathlib import Path\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport random\n\nimg_labels = DP.universe\nprint(len(img_labels))\nprint(img_labels)\n\n# quick macro for dividing a database into two disjunct ones based on a function that returns boolean\ndef filter(dataframe, key, lb, yes, no):\n    for i, k in enumerate(dataframe[key].tolist()):\n        try:\n            if lb(k):\n                yes.loc[len(yes)] = dataframe.iloc[i]\n            else:\n                if no is not None:\n                    no.loc[len(no)] = dataframe.iloc[i]\n        except KeyError:\n            raise KeyError(f'Failed at {k}, {i}')\n            \n\ntrain = pd.DataFrame(columns=['image', 'cultivar'])\ntest = pd.DataFrame(columns=['image', 'cultivar'])\nimg_to_split = pd.DataFrame(columns=['image', 'cultivar'])\n\n# isolate all class with only 1 training sample and put them in train\ncounts = img_labels['cultivar'].value_counts()\nprint(counts)\nfilter(img_labels, 'cultivar', lambda cultivar: counts[cultivar] == 1, train, img_to_split)\n\n\nimgs = img_to_split['image'].tolist()\nlabels = img_to_split['cultivar'].tolist()\n\nprint(len(imgs), len(labels))\n\n# use train_test_split with stratify to split class with multiple training samples\ntrain_split, test_split = train_test_split(imgs, test_size=DP.test_size, stratify=labels)\n# print('train', train_split)\n# print('test_split', test_split, len(test_split))\n\nfilter(img_to_split, 'image', lambda image: image in train_split, train, test)\n\n# print('train', train)\n# print('test', test)\n\nassert(len(img_labels) == len(train) + len(test))\n\ntrain.to_csv(DP.filepaths['train'], index=False)\ntest.to_csv(DP.filepaths['test'], index=False)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Define the dataset",
   "metadata": {
    "tags": [],
    "cell_id": "00007-96257bb4-5cb6-462e-aea0-8e7f5ab7f8e5",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cf9d8389",
    "execution_start": 1650122941844,
    "execution_millis": 40,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:24.958933Z",
     "iopub.execute_input": "2022-04-17T04:41:24.959336Z",
     "iopub.status.idle": "2022-04-17T04:41:25.04849Z",
     "shell.execute_reply.started": "2022-04-17T04:41:24.9593Z",
     "shell.execute_reply": "2022-04-17T04:41:25.047733Z"
    },
    "trusted": true,
    "cell_id": "00008-3ec2dc0e-b6f4-403b-a377-975a2d0583b9",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 981
   },
   "source": "import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision.io import read_image\nfrom torchvision.transforms.functional import convert_image_dtype\nimport cv2\nfrom sklearn import preprocessing\n\nclass CultivarDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n        self.labelenc = preprocessing.LabelEncoder()\n        self.labelenc.fit(self.img_labels['cultivar'].tolist())      \n\n    def to_label(self, string: str):\n        return self.labelenc.transform([string])[0]  \n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n\n        # NOTE: when pytorch reads an image, it is immediately transformed into a uint8 Tensor with each channel ranging in [0, 255]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        label = self.to_label(self.img_labels.iloc[idx, 1])\n\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.target_transform:\n            label = self.target_transform(label)\n        \n        return image, label\n\n# small test to make sure it's working as intended\nc = CultivarDataset(\n    annotations_file=DP.filepaths['train'],\n    img_dir=DP.imgdirpath\n)\n\nprint(c.to_label('PI_257599'))\nprint(c[0])\nprint(f'Make sure there is no garbage data: {c.img_labels[c.img_labels[\"image\"].str.contains(\"2017\")==False]}')\n    ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a03c797a",
    "execution_start": 1650122941931,
    "execution_millis": 45,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.049836Z",
     "iopub.execute_input": "2022-04-17T04:41:25.050092Z",
     "iopub.status.idle": "2022-04-17T04:41:25.178533Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.050057Z",
     "shell.execute_reply": "2022-04-17T04:41:25.177127Z"
    },
    "trusted": true,
    "cell_id": "00009-eda63d9a-33cd-4e77-af07-cfc791733797",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 333
   },
   "source": "datasets = {\n    'train': CultivarDataset(\n                annotations_file=DP.filepaths['train'],\n                img_dir=DP.imgdirpath,\n                transform=DP.transforms['train']\n            ),\n    'test': CultivarDataset(\n                annotations_file=DP.filepaths['test'],\n                img_dir=DP.imgdirpath,\n                transform=DP.transforms['test']\n            )\n}\n\nprint(datasets['train'][0])\nprint(datasets['test'][0])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e26c063b",
    "execution_start": 1650122941976,
    "execution_millis": 1478,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.180928Z",
     "iopub.execute_input": "2022-04-17T04:41:25.181444Z",
     "iopub.status.idle": "2022-04-17T04:41:25.480645Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.181411Z",
     "shell.execute_reply": "2022-04-17T04:41:25.479804Z"
    },
    "trusted": true,
    "cell_id": "00010-f3b4099a-fee6-4851-abdc-c94b0fd55877",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "data = pd.read_csv(annotation_file_path)\ndata.cultivar.value_counts().hist()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Notes on Hyperparameter:\n- https://arxiv.org/pdf/1803.09820.pdf\n- Momentum is usually always 0.9",
   "metadata": {
    "tags": [],
    "cell_id": "00011-8f53338f-4934-4e0c-8c3d-d83b38dd4d1d",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 128.171875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "45a2a773",
    "execution_start": 1650122943169,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.485559Z",
     "iopub.execute_input": "2022-04-17T04:41:25.487695Z",
     "iopub.status.idle": "2022-04-17T04:41:25.498447Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.487624Z",
     "shell.execute_reply": "2022-04-17T04:41:25.497756Z"
    },
    "trusted": true,
    "cell_id": "00012-b3b5bc86-1079-4650-b5d1-2cde8b4a03da",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 351
   },
   "source": "class CustomEffNet(nn.Module):\n    def __init__(self, model_name='tf_efficientnet_b0_ns', pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.model.get_classifier().in_features\n#         self.model.fc = nn.Linear(in_features, CFG.num_classes)\n        self.model.classifier = nn.Sequential(\n            nn.Linear(in_features, in_features),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(in_features, 100)\n        )\n\n    def forward(self, x):\n        x = self.model(x)\n        return x",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fba592ed",
    "execution_start": 1650122943170,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.505102Z",
     "iopub.execute_input": "2022-04-17T04:41:25.507113Z",
     "iopub.status.idle": "2022-04-17T04:41:25.512854Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.507067Z",
     "shell.execute_reply": "2022-04-17T04:41:25.512162Z"
    },
    "trusted": true,
    "cell_id": "00013-888c8b36-a938-4a33-b4db-4b7b7fcf9cbf",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 189
   },
   "source": "# Hyperparameters\nlr = 1e-4\nmax_lr = 1e-3\nmomentum = 0.9\nweight_decay = 1e-5\nepoches = 40\nbatch_size = 8",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "58385167",
    "execution_start": 1650122943170,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.517446Z",
     "iopub.execute_input": "2022-04-17T04:41:25.519507Z",
     "iopub.status.idle": "2022-04-17T04:41:25.526788Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.51947Z",
     "shell.execute_reply": "2022-04-17T04:41:25.526094Z"
    },
    "trusted": true,
    "cell_id": "00014-1aac17c8-74c3-43cc-a9ca-7aa327a386e2",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 207
   },
   "source": "def set_random_seed(seed=0, deterministic=False):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    if deterministic:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2721b579",
    "execution_start": 1650122943171,
    "execution_millis": 1,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.531488Z",
     "iopub.execute_input": "2022-04-17T04:41:25.533657Z",
     "iopub.status.idle": "2022-04-17T04:41:25.547252Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.533621Z",
     "shell.execute_reply": "2022-04-17T04:41:25.546367Z"
    },
    "trusted": true,
    "cell_id": "00015-31a71d99-c4ef-41d6-89b6-ededf7da97a7",
    "owner_user_id": "9d557d55-fc23-4c8b-b1ac-104ba3539c98",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 603
   },
   "source": "def cultivar_train(model, data_loader_train, optimizer, scheduler, criterion, metric, epoch, summary_writer):\n    model.train()\n    optimizer.zero_grad()\n    loss_meter = AverageMeter()\n    acc_meter = AverageMeter()\n    # total_samples, correct = 0, 0\n    with tqdm(enumerate(data_loader_train), total=len(data_loader_train)) as pbar:\n        for idx, (samples, targets) in pbar:\n            optimizer.zero_grad()\n            samples = samples.cuda()\n            targets = targets.cuda()\n            out = model(samples)\n            loss = criterion(out, targets)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            loss_meter.update(loss.item(), targets.size(0))\n\n            # Calculate accuracy\n            pred = F.softmax(out)\n            acc = metric(pred.argmax(1).cpu(), targets.cpu())\n            acc_meter.update(acc, 1)\n            # _, predicted = torch.max(pred.data, 1)\n            # total_samples += targets.size(0)\n            # correct += (predicted == targets).sum().item()\n            if idx%10==0:\n                summary_writer.add_scalar(f'lr', optimizer.param_groups[0]['lr'], epoch*len(data_loader_train)+idx)\n            pbar.set_description(f\"Train epoch {epoch}, loss: {loss: .4f}, accuracy: {acc: .4f}\")\n\n    return loss_meter.avg, acc_meter.avg",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3e95c8d",
    "execution_start": 1650122943174,
    "execution_millis": 2,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.5528Z",
     "iopub.execute_input": "2022-04-17T04:41:25.555474Z",
     "iopub.status.idle": "2022-04-17T04:41:25.566887Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.555433Z",
     "shell.execute_reply": "2022-04-17T04:41:25.56611Z"
    },
    "trusted": true,
    "cell_id": "00016-0cb51c55-4eb4-4fb0-86ea-ea9d277d0efe",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 477
   },
   "source": "def cultivar_val(model, data_loader_val, criterion, metric, epoch):\n    model.eval()\n    loss_meter = AverageMeter()\n    acc_meter = AverageMeter()\n    # total_samples, correct = 0, 0\n    with tqdm(enumerate(data_loader_val), total=len(data_loader_val)) as pbar:\n        for idx, (samples, targets) in pbar:\n            samples = samples.cuda()\n            targets = targets.cuda()\n            out = model(samples)\n            loss = criterion(out, targets)\n            loss_meter.update(loss.item(), targets.size(0))\n            \n            # Calculate accuracy\n            pred = F.softmax(out)\n            acc = metric(pred.argmax(1).cpu(), targets.cpu())\n            acc_meter.update(acc, 1)\n            # _, predicted = torch.max(pred.data, 1)\n            # total_samples += targets.size(0)\n            # correct += (predicted == targets).sum().item()\n            pbar.set_description(f\"Validation epoch {epoch}, loss: {loss: .4f}, accuracy: {acc: .4f}\")\n    \n    return loss_meter.avg, acc_meter.avg",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "You need to run the `test.csv` and `train.csv` generation in `cultivardataset.ipynb` before running this!",
   "metadata": {
    "tags": [],
    "cell_id": "00017-2c18dacb-2321-4567-8ad2-74216c3148a1",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "\nThe general procedure of k-fold is as follows:\n\n- Shuffle the dataset randomly.\n- Split the dataset into k groups\n- For each unique group:\n    - Take the group as a hold out or test data set\n    - Take the remaining groups as a training data set\n    - Fit a model on the training set and evaluate it on the test set\n    - Retain the evaluation score and discard the model\n- Summarize the skill of the model using the sample of model evaluation scores",
   "metadata": {
    "tags": [],
    "cell_id": "00018-4c841559-393f-46a1-b20b-6aff7d14d90c",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 291.515625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4c858027",
    "execution_start": 1650122943226,
    "execution_millis": 2118,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.571933Z",
     "iopub.execute_input": "2022-04-17T04:41:25.574225Z",
     "iopub.status.idle": "2022-04-17T04:49:44.266994Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.574188Z",
     "shell.execute_reply": "2022-04-17T04:49:44.265945Z"
    },
    "trusted": true,
    "cell_id": "00019-657a5bc7-bb42-4073-a93d-bff6ddb4b666",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1179
   },
   "source": "import timm\n\nset_random_seed(seed=42)\nprint(\"Creating datasets...\")\n\nsummary_writer = SummaryWriter()\n\nprint(\"Validation dataset created\")\ndata_loader_train = torch.utils.data.DataLoader(\n    datasets['train'],\n    batch_size = batch_size,\n    num_workers = 2,\n    shuffle=True,\n    pin_memory = True,\n    drop_last = True\n)\n\ndata_loader_val = torch.utils.data.DataLoader(\n    datasets['test'],\n    batch_size = batch_size,\n    num_workers = 2,\n    shuffle=False,\n    pin_memory = True,\n    drop_last = False\n)\n\nprint(\"Dataloader created\")\nprint(\"Creating model...\")\nmodel = CustomEffNet(model_name='tf_efficientnet_b3_ns', pretrained=True)\nmodel.cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n                                                        epochs=epoches, steps_per_epoch=len(data_loader_train),\n                                                        max_lr=max_lr, pct_start=0.2, \n                                                        div_factor=1e3, final_div_factor=1e3)\ncriterion = nn.CrossEntropyLoss()\nmetric = torchmetrics.Accuracy(threshold=0.5, num_classes=100)\n\nmin_loss = float('inf')\n\nprint(\"Start Training\")\nfor epoch in range(epoches):\n    loss_train, acc_train = cultivar_train(model, data_loader_train, optimizer, scheduler, criterion, metric, epoch, summary_writer)\n    loss_val, acc_val = cultivar_val(model, data_loader_val, criterion, metric, epoch)\n    min_loss = min(min_loss, loss_val)\n    if min_loss == loss_val:\n        save_state = {'model': model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'epoch': epoch\n                }\n\n        save_path = f'ckpt_epoch_{epoch}.pth'\n        print(f\"{save_path} saving...\")\n        torch.save(save_state, save_path)\n        print(f\"{save_path} saved\")\n\n    print(\"Writing to summarywriter...\")\n    summary_writer.add_scalar(f'Loss/train', loss_train, epoch)\n    summary_writer.add_scalar(f'Loss/val', loss_val, epoch)\n    summary_writer.add_scalar(f'Acc/train', acc_train, epoch)\n    summary_writer.add_scalar(f'Acc/val', acc_val, epoch)\n    summary_writer.add_scalar(f'Min_loss', min_loss, epoch)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d841b2e3-7f2f-42e6-ae8e-6cea1c0a3631' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "deepnote_notebook_id": "70fc0417-1255-41f1-bbff-9a925a6d87c6",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}