{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6917b025",
    "execution_start": 1651932828900,
    "execution_millis": 31202,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:38:49.140314Z",
     "iopub.execute_input": "2022-04-17T04:38:49.14102Z",
     "iopub.status.idle": "2022-04-17T04:39:45.638416Z",
     "shell.execute_reply.started": "2022-04-17T04:38:49.140978Z",
     "shell.execute_reply": "2022-04-17T04:39:45.637495Z"
    },
    "trusted": true,
    "cell_id": "ab0dedb4-097c-492e-90bd-95f74f258fea",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 791
   },
   "source": "!pip3 install sklearn\n!pip3 install tqdm\n!pip3 install tensorboardX\n!pip3 install timm\n!pip3 install torchmetrics\n!pip3 install albumentations",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: sklearn in /root/venv/lib/python3.7/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /shared-libs/python3.7/py/lib/python3.7/site-packages (from sklearn) (1.0.2)\nRequirement already satisfied: numpy>=1.14.6 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.21.6)\nRequirement already satisfied: scipy>=1.1.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.7.3)\nRequirement already satisfied: joblib>=0.11 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn->sklearn) (3.1.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n^C\nRequirement already satisfied: tqdm in /shared-libs/python3.7/py/lib/python3.7/site-packages (4.64.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: tensorboardX in /root/venv/lib/python3.7/site-packages (2.5)\nRequirement already satisfied: protobuf>=3.8.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorboardX) (3.20.1)\nRequirement already satisfied: numpy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorboardX) (1.21.6)\nRequirement already satisfied: six in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from tensorboardX) (1.16.0)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: timm in /root/venv/lib/python3.7/site-packages (0.5.4)\nRequirement already satisfied: torchvision in /shared-libs/python3.7/py/lib/python3.7/site-packages (from timm) (0.12.0)\nRequirement already satisfied: torch>=1.4 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from timm) (1.11.0)\nRequirement already satisfied: requests in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchvision->timm) (2.27.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchvision->timm) (9.1.0)\nRequirement already satisfied: numpy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\nRequirement already satisfied: typing-extensions in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from torchvision->timm) (4.2.0)\nRequirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests->torchvision->timm) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->torchvision->timm) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from requests->torchvision->timm) (2.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from requests->torchvision->timm) (1.26.9)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nCollecting torchmetrics\n  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n\u001b[K     |████████████████████████████████| 409 kB 27.5 MB/s \n\u001b[?25hRequirement already satisfied: packaging in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.3.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchmetrics) (1.11.0)\nRequirement already satisfied: numpy>=1.17.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from torchmetrics) (1.21.6)\nCollecting pyDeprecate==0.3.*\n  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from packaging->torchmetrics) (3.0.8)\nRequirement already satisfied: typing-extensions in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\nInstalling collected packages: pyDeprecate, torchmetrics\nSuccessfully installed pyDeprecate-0.3.2 torchmetrics-0.8.2\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\nCollecting albumentations\n  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n\u001b[K     |████████████████████████████████| 102 kB 27.7 MB/s \n\u001b[?25hCollecting scikit-image>=0.16.1\n  Downloading scikit_image-0.19.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n\u001b[K     |████████████████████████████████| 13.5 MB 49.5 MB/s \n\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from albumentations) (1.21.6)\nCollecting qudida>=0.0.4\n  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\nRequirement already satisfied: scipy in /shared-libs/python3.7/py/lib/python3.7/site-packages (from albumentations) (1.7.3)\nCollecting opencv-python-headless>=4.1.1\n  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n\u001b[K     |████████████████████████████████| 47.8 MB 65.0 MB/s \n\u001b[?25hRequirement already satisfied: PyYAML in /shared-libs/python3.7/py/lib/python3.7/site-packages (from albumentations) (6.0)\nCollecting imageio>=2.4.1\n  Downloading imageio-2.19.0-py3-none-any.whl (3.4 MB)\n\u001b[K     |████████████████████████████████| 3.4 MB 42.5 MB/s \n\u001b[?25hRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (9.1.0)\nCollecting networkx>=2.2\n  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n\u001b[K     |████████████████████████████████| 1.9 MB 56.9 MB/s \n\u001b[?25hCollecting tifffile>=2019.7.26\n  Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n\u001b[K     |████████████████████████████████| 178 kB 71.4 MB/s \n\u001b[?25hCollecting PyWavelets>=1.1.1\n  Downloading PyWavelets-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n\u001b[K     |████████████████████████████████| 6.4 MB 50.1 MB/s \n\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (1.0.2)\nRequirement already satisfied: typing-extensions in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from qudida>=0.0.4->albumentations) (4.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.8)\nRequirement already satisfied: joblib>=0.11 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\nInstalling collected packages: imageio, networkx, tifffile, PyWavelets, scikit-image, opencv-python-headless, qudida, albumentations\nSuccessfully installed PyWavelets-1.3.0 albumentations-1.1.0 imageio-2.19.0 networkx-2.6.3 opencv-python-headless-4.5.5.64 qudida-0.0.4 scikit-image-0.19.2 tifffile-2021.11.2\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5c6db781",
    "execution_start": 1651932860100,
    "execution_millis": 3557,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:39:45.640764Z",
     "iopub.execute_input": "2022-04-17T04:39:45.641064Z",
     "iopub.status.idle": "2022-04-17T04:39:45.649087Z",
     "shell.execute_reply.started": "2022-04-17T04:39:45.641009Z",
     "shell.execute_reply": "2022-04-17T04:39:45.648285Z"
    },
    "trusted": true,
    "cell_id": "00001-fa5356e9-5c26-4bec-ae3f-062aef3644cf",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 334.375
   },
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch import optim\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom tensorboardX import SummaryWriter\nfrom timm.utils import AverageMeter\nimport random\nimport torchmetrics",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "File paths to the data",
   "metadata": {
    "tags": [],
    "cell_id": "00002-853127dd-8c81-4ee3-8a85-d0dfe2543ec2",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "14a501c5",
    "execution_start": 1651932863663,
    "execution_millis": 2,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:39:45.650928Z",
     "iopub.execute_input": "2022-04-17T04:39:45.651276Z",
     "iopub.status.idle": "2022-04-17T04:39:45.657584Z",
     "shell.execute_reply.started": "2022-04-17T04:39:45.65118Z",
     "shell.execute_reply": "2022-04-17T04:39:45.656817Z"
    },
    "trusted": true,
    "cell_id": "00003-e7364ebf-747a-4edf-acb1-4aa69f5dfc86",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 189
   },
   "source": "# Kaggle\nannotation_file_path = \"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\"\nimg_dir_path = \"../input/sorghum-id-fgvc-9/train_images\"\n\n# DeepNote\n# annotation_file_path = \"data/train_cultivar_mapping.csv\"\n# img_dir_path = \"data/train_images\"",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1d05c3f5",
    "execution_start": 1651932863680,
    "execution_millis": 1274,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:39:45.660338Z",
     "iopub.execute_input": "2022-04-17T04:39:45.660845Z",
     "iopub.status.idle": "2022-04-17T04:39:45.726951Z",
     "shell.execute_reply.started": "2022-04-17T04:39:45.660814Z",
     "shell.execute_reply": "2022-04-17T04:39:45.726205Z"
    },
    "trusted": true,
    "cell_id": "00004-dc9c3027-bd06-44ca-b5eb-84277e44b48f",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1818.1875
   },
   "source": "import pandas as pd\nimport albumentations as A\nfrom pathlib import Path\nfrom albumentations.core.composition import Compose, OneOf\nfrom albumentations.pytorch import ToTensorV2\n\nclass DatasetParams:\n    img_size = 512\n    test_size = 0.2 # change to 0.2 later\n    filepaths = {\n        'train': Path(\"./\") / \"train.csv\",\n        'test': Path(\"./\") / \"test.csv\"\n    }\n    imgdirpath = img_dir_path\n\n    # mean and std of each color channel\n    # below is that of imagenet \n    norm_mean = [0.485, 0.456, 0.406]\n    norm_std = [0.229, 0.224, 0.225]\n\nDP = DatasetParams\n\nDP.universe = pd.read_csv(Path(\"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\"))\nDP.universe = DP.universe[DP.universe.image != '.DS_Store'] # sanitize inputs and remove the .DS_Store bulls**t\n\nDP.transforms = {\n    'train': Compose([\n                A.RandomResizedCrop(height=DP.img_size, width=DP.img_size),\n                A.Flip(p=0.5),\n                A.RandomRotate90(p=0.5),\n                A.ShiftScaleRotate(p=0.5),\n                A.HueSaturationValue(p=0.5),\n                A.OneOf([\n                    A.RandomBrightnessContrast(p=0.5),\n                    A.RandomGamma(p=0.5),\n                ], p=0.5),\n                A.OneOf([\n                    A.Blur(p=0.1),\n                    A.GaussianBlur(p=0.1),\n                    A.MotionBlur(p=0.1),\n                ], p=0.1),\n                A.OneOf([\n                    A.GaussNoise(p=0.1),\n                    A.ISONoise(p=0.1),\n                    A.GridDropout(ratio=0.5, p=0.2),\n                    A.CoarseDropout(max_holes=16, min_holes=8, max_height=16, max_width=16, min_height=8, min_width=8, p=0.2)\n                ], p=0.2),\n                A.Normalize(\n                    mean=DP.norm_mean,\n                    std=DP.norm_std,\n                ),\n                ToTensorV2(),\n            ]),\n    \n    'test': Compose([\n                A.Resize(height=DP.img_size, width=DP.img_size),\n                A.Normalize(\n                    mean=DP.norm_mean,\n                    std=DP.norm_std,\n                ),\n                ToTensorV2(),\n            ])\n}\n\nDP.transforms_vis = {\n    'train': Compose([\n                A.RandomResizedCrop(height=DP.img_size, width=DP.img_size),\n                A.Flip(p=0.5),\n                A.RandomRotate90(p=0.5),\n                A.ShiftScaleRotate(p=0.5),\n                A.HueSaturationValue(p=0.5),\n                A.OneOf([\n                    A.RandomBrightnessContrast(p=0.5),\n                    A.RandomGamma(p=0.5),\n                ], p=0.5),\n                A.OneOf([\n                    A.Blur(p=0.1),\n                    A.GaussianBlur(p=0.1),\n                    A.MotionBlur(p=0.1),\n                ], p=0.1),\n                A.OneOf([\n                    A.GaussNoise(p=0.1),\n                    A.ISONoise(p=0.1),\n                    A.GridDropout(ratio=0.5, p=0.2),\n                    A.CoarseDropout(max_holes=16, min_holes=8, max_height=16, max_width=16, min_height=8, min_width=8, p=0.2)\n                ], p=0.2),\n                ToTensorV2(),\n            ]),\n    \n    'test': Compose([\n                A.Resize(height=DP.img_size, width=DP.img_size),\n                ToTensorV2(),\n            ])\n}",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d686c610fd5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mDP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mDP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mDP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniverse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'.DS_Store'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# sanitize inputs and remove the .DS_Store bulls**t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             )\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Split data into train and test ",
   "metadata": {
    "tags": [],
    "cell_id": "00005-d65d7203-8825-4c40-ad0f-fbdc43236550",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b0da488c",
    "execution_start": 1650122941083,
    "execution_millis": 755,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:39:45.728095Z",
     "iopub.execute_input": "2022-04-17T04:39:45.728419Z",
     "iopub.status.idle": "2022-04-17T04:41:24.957249Z",
     "shell.execute_reply.started": "2022-04-17T04:39:45.728382Z",
     "shell.execute_reply": "2022-04-17T04:41:24.956453Z"
    },
    "trusted": true,
    "cell_id": "00006-9292c026-ec98-44a5-9bc1-e18cadf6a05d",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 981
   },
   "source": "from pathlib import Path\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport random\n\nimg_labels = DP.universe\nprint(len(img_labels))\nprint(img_labels)\n\n# quick macro for dividing a database into two disjunct ones based on a function that returns boolean\ndef filter(dataframe, key, lb, yes, no):\n    for i, k in enumerate(dataframe[key].tolist()):\n        try:\n            if lb(k):\n                yes.loc[len(yes)] = dataframe.iloc[i]\n            else:\n                if no is not None:\n                    no.loc[len(no)] = dataframe.iloc[i]\n        except KeyError:\n            raise KeyError(f'Failed at {k}, {i}')\n            \n\ntrain = pd.DataFrame(columns=['image', 'cultivar'])\ntest = pd.DataFrame(columns=['image', 'cultivar'])\nimg_to_split = pd.DataFrame(columns=['image', 'cultivar'])\n\n# isolate all class with only 1 training sample and put them in train\ncounts = img_labels['cultivar'].value_counts()\nprint(counts)\nfilter(img_labels, 'cultivar', lambda cultivar: counts[cultivar] == 1, train, img_to_split)\n\n\nimgs = img_to_split['image'].tolist()\nlabels = img_to_split['cultivar'].tolist()\n\nprint(len(imgs), len(labels))\n\n# use train_test_split with stratify to split class with multiple training samples\ntrain_split, test_split = train_test_split(imgs, test_size=DP.test_size, stratify=labels)\n# print('train', train_split)\n# print('test_split', test_split, len(test_split))\n\nfilter(img_to_split, 'image', lambda image: image in train_split, train, test)\n\n# print('train', train)\n# print('test', test)\n\nassert(len(img_labels) == len(train) + len(test))\n\ntrain.to_csv(DP.filepaths['train'], index=False)\ntest.to_csv(DP.filepaths['test'], index=False)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Define the dataset",
   "metadata": {
    "tags": [],
    "cell_id": "00007-96257bb4-5cb6-462e-aea0-8e7f5ab7f8e5",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "cf9d8389",
    "execution_start": 1650733741653,
    "execution_millis": 34,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:24.958933Z",
     "iopub.execute_input": "2022-04-17T04:41:24.959336Z",
     "iopub.status.idle": "2022-04-17T04:41:25.04849Z",
     "shell.execute_reply.started": "2022-04-17T04:41:24.9593Z",
     "shell.execute_reply": "2022-04-17T04:41:25.047733Z"
    },
    "trusted": true,
    "cell_id": "00008-3ec2dc0e-b6f4-403b-a377-975a2d0583b9",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1044.1875
   },
   "source": "import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision.io import read_image\nfrom torchvision.transforms.functional import convert_image_dtype\nimport cv2\nfrom sklearn import preprocessing\n\nclass CultivarDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n        self.labelenc = preprocessing.LabelEncoder()\n        self.labelenc.fit(self.img_labels['cultivar'].tolist())      \n\n    def to_label(self, string: str):\n        return self.labelenc.transform([string])[0]  \n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n\n        # NOTE: when pytorch reads an image, it is immediately transformed into a uint8 Tensor with each channel ranging in [0, 255]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        label = self.to_label(self.img_labels.iloc[idx, 1])\n\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.target_transform:\n            label = self.target_transform(label)\n        \n        return image, label\n\n# small test to make sure it's working as intended\nc = CultivarDataset(\n    annotations_file=DP.filepaths['train'],\n    img_dir=DP.imgdirpath\n)\n\nprint(c.to_label('PI_257599'))\nprint(c[0])\nprint(f'Make sure there is no garbage data: {c.img_labels[c.img_labels[\"image\"].str.contains(\"2017\")==False]}')\n    ",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6a8f2306d196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m c = CultivarDataset(\n\u001b[1;32m     44\u001b[0m     \u001b[0mannotations_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mimg_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgdirpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-6a8f2306d196>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, annotations_file, img_dir, transform, target_transform)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCultivarDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             )\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "a03c797a",
    "execution_start": 1650122941931,
    "execution_millis": 45,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.049836Z",
     "iopub.execute_input": "2022-04-17T04:41:25.050092Z",
     "iopub.status.idle": "2022-04-17T04:41:25.178533Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.050057Z",
     "shell.execute_reply": "2022-04-17T04:41:25.177127Z"
    },
    "trusted": true,
    "cell_id": "00009-eda63d9a-33cd-4e77-af07-cfc791733797",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 333
   },
   "source": "datasets = {\n    'train': CultivarDataset(\n                annotations_file=DP.filepaths['train'],\n                img_dir=DP.imgdirpath,\n                transform=DP.transforms['train']\n            ),\n    'test': CultivarDataset(\n                annotations_file=DP.filepaths['test'],\n                img_dir=DP.imgdirpath,\n                transform=DP.transforms['test']\n            )\n}\n\nprint(datasets['train'][0])\nprint(datasets['test'][0])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "e26c063b",
    "execution_start": 1650122941976,
    "execution_millis": 1478,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.180928Z",
     "iopub.execute_input": "2022-04-17T04:41:25.181444Z",
     "iopub.status.idle": "2022-04-17T04:41:25.480645Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.181411Z",
     "shell.execute_reply": "2022-04-17T04:41:25.479804Z"
    },
    "trusted": true,
    "cell_id": "00010-f3b4099a-fee6-4851-abdc-c94b0fd55877",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "data = pd.read_csv(annotation_file_path)\ndata.cultivar.value_counts().hist()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Notes on Hyperparameter:\n- https://arxiv.org/pdf/1803.09820.pdf\n- Momentum is usually always 0.9",
   "metadata": {
    "tags": [],
    "cell_id": "00011-8f53338f-4934-4e0c-8c3d-d83b38dd4d1d",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 128.171875
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "45a2a773",
    "execution_start": 1650122943169,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.485559Z",
     "iopub.execute_input": "2022-04-17T04:41:25.487695Z",
     "iopub.status.idle": "2022-04-17T04:41:25.498447Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.487624Z",
     "shell.execute_reply": "2022-04-17T04:41:25.497756Z"
    },
    "trusted": true,
    "cell_id": "00012-b3b5bc86-1079-4650-b5d1-2cde8b4a03da",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 351
   },
   "source": "class CustomEffNet(nn.Module):\n    def __init__(self, model_name='tf_efficientnet_b0_ns', pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.model.get_classifier().in_features\n#         self.model.fc = nn.Linear(in_features, CFG.num_classes)\n        self.model.classifier = nn.Sequential(\n            nn.Linear(in_features, in_features),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(in_features, 100)\n        )\n\n    def forward(self, x):\n        x = self.model(x)\n        return x",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "f4709fb6",
    "execution_start": 1650122943170,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.505102Z",
     "iopub.execute_input": "2022-04-17T04:41:25.507113Z",
     "iopub.status.idle": "2022-04-17T04:41:25.512854Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.507067Z",
     "shell.execute_reply": "2022-04-17T04:41:25.512162Z"
    },
    "trusted": true,
    "cell_id": "00013-888c8b36-a938-4a33-b4db-4b7b7fcf9cbf",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 189
   },
   "source": "# Hyperparameters\nlr = 1e-4\nmax_lr = 1e-3\nmomentum = 0.9\nweight_decay = 1e-5\nepoches = 40\nbatch_size = 8",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "58385167",
    "execution_start": 1650122943170,
    "execution_millis": 0,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.517446Z",
     "iopub.execute_input": "2022-04-17T04:41:25.519507Z",
     "iopub.status.idle": "2022-04-17T04:41:25.526788Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.51947Z",
     "shell.execute_reply": "2022-04-17T04:41:25.526094Z"
    },
    "trusted": true,
    "cell_id": "00014-1aac17c8-74c3-43cc-a9ca-7aa327a386e2",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 207
   },
   "source": "def set_random_seed(seed=0, deterministic=False):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    if deterministic:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "7c594c39",
    "execution_start": 1650122943171,
    "execution_millis": 1,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.531488Z",
     "iopub.execute_input": "2022-04-17T04:41:25.533657Z",
     "iopub.status.idle": "2022-04-17T04:41:25.547252Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.533621Z",
     "shell.execute_reply": "2022-04-17T04:41:25.546367Z"
    },
    "trusted": true,
    "cell_id": "00015-31a71d99-c4ef-41d6-89b6-ededf7da97a7",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 603
   },
   "source": "def cultivar_train(model, data_loader_train, optimizer, scheduler, criterion, metric, epoch, summary_writer):\n    model.train()\n    optimizer.zero_grad()\n    loss_meter = AverageMeter()\n    acc_meter = AverageMeter()\n    # total_samples, correct = 0, 0\n    with tqdm(enumerate(data_loader_train), total=len(data_loader_train)) as pbar:\n        for idx, (samples, targets) in pbar:\n            optimizer.zero_grad()\n            samples = samples.cuda()\n            targets = targets.cuda()\n            out = model(samples)\n            loss = criterion(out, targets)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            loss_meter.update(loss.item(), targets.size(0))\n\n            # Calculate accuracy\n            pred = F.softmax(out)\n            acc = metric(pred.argmax(1).cpu(), targets.cpu())\n            acc_meter.update(acc, 1)\n            # _, predicted = torch.max(pred.data, 1)\n            # total_samples += targets.size(0)\n            # correct += (predicted == targets).sum().item()\n            if idx%10==0:\n                summary_writer.add_scalar(f'lr', optimizer.param_groups[0]['lr'], epoch*len(data_loader_train)+idx)\n            pbar.set_description(f\"Train epoch {epoch}, loss: {loss: .4f}, accuracy: {acc: .4f}\")\n\n    return loss_meter.avg, acc_meter.avg",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "11b7432f",
    "execution_start": 1650122943174,
    "execution_millis": 2,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.5528Z",
     "iopub.execute_input": "2022-04-17T04:41:25.555474Z",
     "iopub.status.idle": "2022-04-17T04:41:25.566887Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.555433Z",
     "shell.execute_reply": "2022-04-17T04:41:25.56611Z"
    },
    "trusted": true,
    "cell_id": "00016-0cb51c55-4eb4-4fb0-86ea-ea9d277d0efe",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 477
   },
   "source": "def cultivar_val(model, data_loader_val, criterion, metric, epoch):\n    model.eval()\n    loss_meter = AverageMeter()\n    acc_meter = AverageMeter()\n    # total_samples, correct = 0, 0\n    with tqdm(enumerate(data_loader_val), total=len(data_loader_val)) as pbar:\n        for idx, (samples, targets) in pbar:\n            samples = samples.cuda()\n            targets = targets.cuda()\n            out = model(samples)\n            loss = criterion(out, targets)\n            loss_meter.update(loss.item(), targets.size(0))\n            \n            # Calculate accuracy\n            pred = F.softmax(out)\n            acc = metric(pred.argmax(1).cpu(), targets.cpu())\n            acc_meter.update(acc, 1)\n            # _, predicted = torch.max(pred.data, 1)\n            # total_samples += targets.size(0)\n            # correct += (predicted == targets).sum().item()\n            pbar.set_description(f\"Validation epoch {epoch}, loss: {loss: .4f}, accuracy: {acc: .4f}\")\n    \n    return loss_meter.avg, acc_meter.avg",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "You need to run the `test.csv` and `train.csv` generation in `cultivardataset.ipynb` before running this!",
   "metadata": {
    "tags": [],
    "cell_id": "00017-2c18dacb-2321-4567-8ad2-74216c3148a1",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "\nThe general procedure of k-fold is as follows:\n\n- Shuffle the dataset randomly.\n- Split the dataset into k groups\n- For each unique group:\n    - Take the group as a hold out or test data set\n    - Take the remaining groups as a training data set\n    - Fit a model on the training set and evaluate it on the test set\n    - Retain the evaluation score and discard the model\n- Summarize the skill of the model using the sample of model evaluation scores",
   "metadata": {
    "tags": [],
    "cell_id": "00018-4c841559-393f-46a1-b20b-6aff7d14d90c",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 291.515625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "fad1c3cb",
    "execution_start": 1650122943226,
    "execution_millis": 2118,
    "execution": {
     "iopub.status.busy": "2022-04-17T04:41:25.571933Z",
     "iopub.execute_input": "2022-04-17T04:41:25.574225Z",
     "iopub.status.idle": "2022-04-17T04:49:44.266994Z",
     "shell.execute_reply.started": "2022-04-17T04:41:25.574188Z",
     "shell.execute_reply": "2022-04-17T04:49:44.265945Z"
    },
    "trusted": true,
    "cell_id": "00019-657a5bc7-bb42-4073-a93d-bff6ddb4b666",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1179
   },
   "source": "import timm\n\nset_random_seed(seed=42)\nprint(\"Creating datasets...\")\n\nsummary_writer = SummaryWriter()\n\nprint(\"Validation dataset created\")\ndata_loader_train = torch.utils.data.DataLoader(\n    datasets['train'],\n    batch_size = batch_size,\n    num_workers = 2,\n    shuffle=True,\n    pin_memory = True,\n    drop_last = True\n)\n\ndata_loader_val = torch.utils.data.DataLoader(\n    datasets['test'],\n    batch_size = batch_size,\n    num_workers = 2,\n    shuffle=False,\n    pin_memory = True,\n    drop_last = False\n)\n\nprint(\"Dataloader created\")\nprint(\"Creating model...\")\nmodel = CustomEffNet(model_name='tf_efficientnet_b3_ns', pretrained=True)\nmodel.cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n                                                        epochs=epoches, steps_per_epoch=len(data_loader_train),\n                                                        max_lr=max_lr, pct_start=0.2, \n                                                        div_factor=1e3, final_div_factor=1e3)\ncriterion = nn.CrossEntropyLoss()\nmetric = torchmetrics.Accuracy(threshold=0.5, num_classes=100)\n\nmin_loss = float('inf')\n\nprint(\"Start Training\")\nfor epoch in range(epoches):\n    loss_train, acc_train = cultivar_train(model, data_loader_train, optimizer, scheduler, criterion, metric, epoch, summary_writer)\n    loss_val, acc_val = cultivar_val(model, data_loader_val, criterion, metric, epoch)\n    min_loss = min(min_loss, loss_val)\n    if min_loss == loss_val:\n        save_state = {'model': model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'epoch': epoch\n                }\n\n        save_path = f'ckpt_epoch_{epoch}.pth'\n        print(f\"{save_path} saving...\")\n        torch.save(save_state, save_path)\n        print(f\"{save_path} saved\")\n\n    print(\"Writing to summarywriter...\")\n    summary_writer.add_scalar(f'Loss/train', loss_train, epoch)\n    summary_writer.add_scalar(f'Loss/val', loss_val, epoch)\n    summary_writer.add_scalar(f'Acc/train', acc_train, epoch)\n    summary_writer.add_scalar(f'Acc/val', acc_val, epoch)\n    summary_writer.add_scalar(f'Min_loss', min_loss, epoch)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d841b2e3-7f2f-42e6-ae8e-6cea1c0a3631' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "deepnote_notebook_id": "70fc0417-1255-41f1-bbff-9a925a6d87c6",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}